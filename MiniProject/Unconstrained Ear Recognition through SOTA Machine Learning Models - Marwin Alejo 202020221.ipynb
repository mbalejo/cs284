{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CS284_MiniProject_MarwinAlejo_202020221.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyONNyToyxtEfuWVT8AcZseG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mbalejo/CS284/blob/main/Unconstrained%20Ear%20Recognition%20through%20SOTA%20Machine%20Learning%20Models%20-%20Marwin%20Alejo%20202020221.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**CS284 Mini-Project**\n",
        "\n",
        "**Codes for Unconstrained Ear Recognition using SOTA ML Models **\n",
        "\n",
        "*Marwin B. Alejo*\n",
        "\n",
        "*2020-20221*"
      ],
      "metadata": {
        "id": "IWKcGhLCc1eZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This notebook contain straightforward codeblocks hence, required libraries will be installed when each cell was executed."
      ],
      "metadata": {
        "id": "x9DVsnibuv7t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**ResNet18**"
      ],
      "metadata": {
        "id": "N9jXXF7uYNpE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install timm\n",
        "!CUDA_LAUNCH_BLOCKING=1\n",
        "import os\n",
        "import cv2\n",
        "import sys\n",
        "import json\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from functools import partial\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "from torch import nn\n",
        "from timm.utils import accuracy\n",
        "from timm.data import Mixup\n",
        "from timm.models import create_model\n",
        "from timm.loss import LabelSmoothingCrossEntropy, SoftTargetCrossEntropy\n",
        "from timm.scheduler import create_scheduler\n",
        "import torchvision.transforms as transforms\n",
        "from timm.optim import create_optimizer\n",
        "from timm.utils import NativeScaler, get_state_dict, ModelEma\n",
        "from timm.models.registry import register_model\n",
        "from timm.models.mlp_mixer import ResBlock, Affine, _create_mixer, _cfg\n",
        "from timm.models import create_model, resnet\n",
        "from timm.models.resnet import BasicBlock, Bottleneck, ResNet, _create_resnet\n",
        "import torchvision\n",
        "import numpy as np\n",
        "import collections\n",
        "import math\n",
        "from datetime import datetime\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive/', force_remount=True)\n",
        "\n",
        "# Modify these code line by specifying the path of Train and Test data as well as the path for saving the model.\n",
        "TRAIN_PATH = \"/content/drive/MyDrive/Colab_Notebooks/ViT-Ear/EarVN/train/\"\n",
        "TEST_PATH = \"/content/drive/MyDrive/Colab_Notebooks/ViT-Ear/EarVN/val/\"\n",
        "MODEL_PATH = \"/content/drive/MyDrive/Colab_Notebooks/ViT-Ear/EarVN/model/resnet18.pth\"\n",
        "\n",
        "image_size = 224\n",
        "IMG_SIZE = 224\n",
        "BATCH_SIZE = 32\n",
        "LR = 2e-05\n",
        "GAMMA = 0.7\n",
        "N_EPOCHS = 20\n",
        "N_CLASSES = 20\n",
        "\n",
        "def get_loaders(batch_size = BATCH_SIZE, num_workers=2):\n",
        "  transforms_train = transforms.Compose(\n",
        "    [\n",
        "        transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
        "        transforms.RandomHorizontalFlip(p=0.3),\n",
        "        transforms.RandomVerticalFlip(p=0.3),\n",
        "        transforms.RandomResizedCrop(IMG_SIZE),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n",
        "    ])\n",
        "\n",
        "  transforms_valid = torchvision.transforms.Compose(\n",
        "      [\n",
        "          transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
        "          transforms.ToTensor(),\n",
        "          transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n",
        "      ]\n",
        "  )\n",
        "\n",
        "  train_dataset = torchvision.datasets.ImageFolder(TRAIN_PATH, transform = transforms_train)\n",
        "  valid_dataset = torchvision.datasets.ImageFolder(TEST_PATH, transform = transforms_valid)\n",
        "\n",
        "  train_loader = torch.utils.data.DataLoader(\n",
        "      train_dataset,\n",
        "      batch_size=batch_size,\n",
        "      shuffle=True,\n",
        "      num_workers=num_workers,\n",
        "      drop_last=True,\n",
        "    )\n",
        "\n",
        "  valid_loader = torch.utils.data.DataLoader(\n",
        "      valid_dataset,\n",
        "      batch_size=batch_size,\n",
        "      shuffle=False,\n",
        "      num_workers=num_workers,\n",
        "      drop_last=True,\n",
        "    )\n",
        "\n",
        "  loaders = collections.OrderedDict()\n",
        "  loaders[\"train\"] = train_loader\n",
        "  loaders[\"valid\"] = valid_loader\n",
        "\n",
        "  return loaders\n",
        "\n",
        "@register_model\n",
        "def resnet18(pretrained=False, **kwargs):\n",
        "  \"\"\"Constructs a ResNet-18 model.\"\"\"\n",
        "  model_args = dict(block=BasicBlock, layers=[2, 2, 2, 2], **kwargs)\n",
        "  return model\n",
        "\n",
        "model = create_model(\n",
        "    'resnet18',\n",
        "    pretrained=True,\n",
        "    num_classes=20)\n",
        "\n",
        "model_ema = ModelEma(\n",
        "    model,\n",
        "    decay=0.99,\n",
        "    device='cuda'\n",
        ")\n",
        "\n",
        "n_parameters = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "print('number of params:', n_parameters)\n",
        "\n",
        "linear_scaled_lr = 0.0001 * BATCH_SIZE * 1 / 512.0\n",
        "lr = linear_scaled_lr\n",
        "optimizer  = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "loss_scaler = NativeScaler()\n",
        "\n",
        "lr_scheduler =torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, 0.001)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "mixup_fn = Mixup(\n",
        "            mixup_alpha=0.2, cutmix_alpha=0.03, \n",
        "            prob=0.8, switch_prob=0.3, mode= 'batch', num_classes=20)\n",
        "\n",
        "@torch.no_grad()\n",
        "def evaluate(data_loader, model, device):\n",
        "    criterion = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "\n",
        "    # switch to evaluation mode\n",
        "    model.eval()\n",
        "    acc1_mean = 0.0\n",
        "    acc5_mean = 0.0\n",
        "    Batch = len(data_loader)\n",
        "    print('Total Batch:', Batch)\n",
        "    \n",
        "    for images, target in data_loader:\n",
        "        images = images.to(device, non_blocking=True)\n",
        "        target = target.to(device, non_blocking=True)\n",
        "\n",
        "        # compute output\n",
        "        with torch.cuda.amp.autocast():\n",
        "            output = model(images)\n",
        "            loss = criterion(output, target)\n",
        "\n",
        "        acc1, acc5 = accuracy(output, target, topk=(1, 5))\n",
        "        acc1_mean+=acc1.item()\n",
        "        acc5_mean+=acc5.item()\n",
        "        \n",
        "\n",
        "        batch_size = images.shape[0]\n",
        "    print('* Acc@1 {:.3f} Acc@5 {:.3f} loss {:.3f}'\n",
        "          .format(acc1_mean/Batch, acc5_mean/Batch, loss.item()))\n",
        "    \n",
        "def train_one_epoch(model, criterion, data_loader, optimizer,\n",
        "                    device, epoch, loss_scaler, max_norm,\n",
        "                    model_ema, mixup_fn):\n",
        "\n",
        "    model.train()\n",
        "    model.to(device)\n",
        "    header = 'Epoch: [{}]'.format(epoch)\n",
        "    print_freq = 50\n",
        "    count = 0\n",
        "    Batch = len(data_loader)\n",
        "    print('Total Batch:', Batch)\n",
        "    loss_mean = 0.0\n",
        "    for samples, targets in data_loader:\n",
        "        count +=1\n",
        "        samples = samples.to(device, non_blocking=True)\n",
        "        targets = targets.to(device, non_blocking=True)\n",
        "\n",
        "        if mixup_fn is not None:\n",
        "            samples, _ = mixup_fn(samples, targets)\n",
        "        with torch.cuda.amp.autocast():\n",
        "            outputs = model(samples)\n",
        "            \n",
        "            loss = criterion(outputs, targets)\n",
        "\n",
        "        loss_value = loss.item()\n",
        "        loss_mean += loss_value \n",
        "\n",
        "        if not math.isfinite(loss_value):\n",
        "            print(\"Loss is {}, stopping training\".format(loss_value))\n",
        "            sys.exit(1)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # this attribute is added by timm on one optimizer (adahessian)\n",
        "        is_second_order = hasattr(optimizer, 'is_second_order') and optimizer.is_second_order\n",
        "        loss_scaler(loss, optimizer, clip_grad=max_norm,\n",
        "                    parameters=model.parameters(), create_graph=is_second_order)\n",
        "\n",
        "        torch.cuda.synchronize()\n",
        "        if model_ema is not None:\n",
        "            model_ema.update(model)\n",
        "\n",
        "        if count % print_freq == 0:\n",
        "            current_time = datetime.now().strftime(\"%H:%M:%S\")\n",
        "            print(f'{current_time}\\tEPOCH: [{epoch}/10] STEP: [{count}/{Batch}], LOSS: {loss_mean/50}')\n",
        "            loss_mean = 0.0\n",
        "    torch.save({'model': model.state_dict(),\n",
        "                'optimizer': optimizer.state_dict(),\n",
        "                'lr_scheduler': lr_scheduler.state_dict(),\n",
        "                'epoch': epoch,\n",
        "                'model_ema': get_state_dict(model_ema),\n",
        "                }, MODEL_PATH)\n",
        "\n",
        "loaders = get_loaders()\n",
        "\n",
        "print(\"Start training\")\n",
        "max_accuracy = 0.0\n",
        "for epoch in range(0, 19):\n",
        "\n",
        "    train_stats = train_one_epoch(\n",
        "        model, criterion, loaders[\"train\"],\n",
        "        optimizer, 'cuda', epoch, loss_scaler,\n",
        "        None, model_ema, mixup_fn\n",
        "    )\n",
        "\n",
        "    lr_scheduler.step(epoch)\n",
        "    evaluate( loaders[\"valid\"], model, 'cuda')\n"
      ],
      "metadata": {
        "id": "rbETgl6lYRV9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**ResNet50**"
      ],
      "metadata": {
        "id": "cQEsi3yyZELm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install timm\n",
        "!CUDA_LAUNCH_BLOCKING=1\n",
        "import os\n",
        "import cv2\n",
        "import sys\n",
        "import json\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from functools import partial\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "from torch import nn\n",
        "from timm.utils import accuracy\n",
        "from timm.data import Mixup\n",
        "from timm.models import create_model\n",
        "from timm.loss import LabelSmoothingCrossEntropy, SoftTargetCrossEntropy\n",
        "from timm.scheduler import create_scheduler\n",
        "import torchvision.transforms as transforms\n",
        "from timm.optim import create_optimizer\n",
        "from timm.utils import NativeScaler, get_state_dict, ModelEma\n",
        "from timm.models.registry import register_model\n",
        "from timm.models.mlp_mixer import ResBlock, Affine, _create_mixer, _cfg\n",
        "from timm.models import create_model, resnet\n",
        "from timm.models.resnet import BasicBlock, Bottleneck, ResNet, _create_resnet\n",
        "import torchvision\n",
        "import numpy as np\n",
        "import collections\n",
        "import math\n",
        "from datetime import datetime\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive/', force_remount=True)\n",
        "\n",
        "# Modify these code line by specifying the path of Train and Test data as well as the path for saving the model.\n",
        "TRAIN_PATH = \"/content/drive/MyDrive/Colab_Notebooks/ViT-Ear/EarVN/train/\"\n",
        "TEST_PATH = \"/content/drive/MyDrive/Colab_Notebooks/ViT-Ear/EarVN/val/\"\n",
        "MODEL_PATH = \"/content/drive/MyDrive/Colab_Notebooks/ViT-Ear/EarVN/model/resnet50.pth\"\n",
        "\n",
        "image_size = 224\n",
        "IMG_SIZE = 224\n",
        "BATCH_SIZE = 32\n",
        "LR = 2e-05\n",
        "GAMMA = 0.7\n",
        "N_EPOCHS = 20\n",
        "N_CLASSES = 20\n",
        "\n",
        "def get_loaders(batch_size = BATCH_SIZE, num_workers=2):\n",
        "  transforms_train = transforms.Compose(\n",
        "    [\n",
        "        transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
        "        transforms.RandomHorizontalFlip(p=0.3),\n",
        "        transforms.RandomVerticalFlip(p=0.3),\n",
        "        transforms.RandomResizedCrop(IMG_SIZE),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n",
        "    ])\n",
        "\n",
        "  transforms_valid = torchvision.transforms.Compose(\n",
        "      [\n",
        "          transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
        "          transforms.ToTensor(),\n",
        "          transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n",
        "      ]\n",
        "  )\n",
        "\n",
        "  train_dataset = torchvision.datasets.ImageFolder(TRAIN_PATH, transform = transforms_train)\n",
        "  valid_dataset = torchvision.datasets.ImageFolder(TEST_PATH, transform = transforms_valid)\n",
        "\n",
        "  train_loader = torch.utils.data.DataLoader(\n",
        "      train_dataset,\n",
        "      batch_size=batch_size,\n",
        "      shuffle=True,\n",
        "      num_workers=num_workers,\n",
        "      drop_last=True,\n",
        "    )\n",
        "\n",
        "  valid_loader = torch.utils.data.DataLoader(\n",
        "      valid_dataset,\n",
        "      batch_size=batch_size,\n",
        "      shuffle=False,\n",
        "      num_workers=num_workers,\n",
        "      drop_last=True,\n",
        "    )\n",
        "\n",
        "  loaders = collections.OrderedDict()\n",
        "  loaders[\"train\"] = train_loader\n",
        "  loaders[\"valid\"] = valid_loader\n",
        "\n",
        "  return loaders\n",
        "\n",
        "@register_model\n",
        "def resnet50(pretrained=False, **kwargs):\n",
        "  \"\"\"Constructs a ResNet-50 model\"\"\"\n",
        "  model_args = dict(block=Bottleneck, layers=[3, 4, 6, 3],  **kwargs)\n",
        "  model = _create_resnet('resnet50', pretrained, **model_args)\n",
        "  return model\n",
        "\n",
        "model = create_model(\n",
        "    'resnet50',\n",
        "    pretrained=True,\n",
        "    num_classes=20)\n",
        "\n",
        "model_ema = ModelEma(\n",
        "    model,\n",
        "    decay=0.99,\n",
        "    device='cuda'\n",
        ")\n",
        "\n",
        "n_parameters = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "print('number of params:', n_parameters)\n",
        "\n",
        "linear_scaled_lr = 0.0001 * BATCH_SIZE * 1 / 512.0\n",
        "lr = linear_scaled_lr\n",
        "optimizer  = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "loss_scaler = NativeScaler()\n",
        "\n",
        "lr_scheduler =torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, 0.001)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "mixup_fn = Mixup(\n",
        "            mixup_alpha=0.2, cutmix_alpha=0.03, \n",
        "            prob=0.8, switch_prob=0.3, mode= 'batch', num_classes=20)\n",
        "\n",
        "@torch.no_grad()\n",
        "def evaluate(data_loader, model, device):\n",
        "    criterion = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "\n",
        "    # switch to evaluation mode\n",
        "    model.eval()\n",
        "    acc1_mean = 0.0\n",
        "    acc5_mean = 0.0\n",
        "    Batch = len(data_loader)\n",
        "    print('Total Batch:', Batch)\n",
        "    \n",
        "    for images, target in data_loader:\n",
        "        images = images.to(device, non_blocking=True)\n",
        "        target = target.to(device, non_blocking=True)\n",
        "\n",
        "        # compute output\n",
        "        with torch.cuda.amp.autocast():\n",
        "            output = model(images)\n",
        "            loss = criterion(output, target)\n",
        "\n",
        "        acc1, acc5 = accuracy(output, target, topk=(1, 5))\n",
        "        acc1_mean+=acc1.item()\n",
        "        acc5_mean+=acc5.item()\n",
        "        \n",
        "\n",
        "        batch_size = images.shape[0]\n",
        "    print('* Acc@1 {:.3f} Acc@5 {:.3f} loss {:.3f}'\n",
        "          .format(acc1_mean/Batch, acc5_mean/Batch, loss.item()))\n",
        "    \n",
        "def train_one_epoch(model, criterion, data_loader, optimizer,\n",
        "                    device, epoch, loss_scaler, max_norm,\n",
        "                    model_ema, mixup_fn):\n",
        "\n",
        "    model.train()\n",
        "    model.to(device)\n",
        "    header = 'Epoch: [{}]'.format(epoch)\n",
        "    print_freq = 50\n",
        "    count = 0\n",
        "    Batch = len(data_loader)\n",
        "    print('Total Batch:', Batch)\n",
        "    loss_mean = 0.0\n",
        "    for samples, targets in data_loader:\n",
        "        count +=1\n",
        "        samples = samples.to(device, non_blocking=True)\n",
        "        targets = targets.to(device, non_blocking=True)\n",
        "\n",
        "        if mixup_fn is not None:\n",
        "            samples, _ = mixup_fn(samples, targets)\n",
        "        with torch.cuda.amp.autocast():\n",
        "            outputs = model(samples)\n",
        "            \n",
        "            loss = criterion(outputs, targets)\n",
        "\n",
        "        loss_value = loss.item()\n",
        "        loss_mean += loss_value \n",
        "\n",
        "        if not math.isfinite(loss_value):\n",
        "            print(\"Loss is {}, stopping training\".format(loss_value))\n",
        "            sys.exit(1)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # this attribute is added by timm on one optimizer (adahessian)\n",
        "        is_second_order = hasattr(optimizer, 'is_second_order') and optimizer.is_second_order\n",
        "        loss_scaler(loss, optimizer, clip_grad=max_norm,\n",
        "                    parameters=model.parameters(), create_graph=is_second_order)\n",
        "\n",
        "        torch.cuda.synchronize()\n",
        "        if model_ema is not None:\n",
        "            model_ema.update(model)\n",
        "\n",
        "        if count % print_freq == 0:\n",
        "            current_time = datetime.now().strftime(\"%H:%M:%S\")\n",
        "            print(f'{current_time}\\tEPOCH: [{epoch}/10] STEP: [{count}/{Batch}], LOSS: {loss_mean/50}')\n",
        "            loss_mean = 0.0\n",
        "    torch.save({'model': model.state_dict(),\n",
        "                'optimizer': optimizer.state_dict(),\n",
        "                'lr_scheduler': lr_scheduler.state_dict(),\n",
        "                'epoch': epoch,\n",
        "                'model_ema': get_state_dict(model_ema),\n",
        "                }, MODEL_PATH)\n",
        "\n",
        "loaders = get_loaders()\n",
        "\n",
        "print(\"Start training\")\n",
        "max_accuracy = 0.0\n",
        "for epoch in range(0, 19):\n",
        "\n",
        "    train_stats = train_one_epoch(\n",
        "        model, criterion, loaders[\"train\"],\n",
        "        optimizer, 'cuda', epoch, loss_scaler,\n",
        "        None, model_ema, mixup_fn\n",
        "    )\n",
        "\n",
        "    lr_scheduler.step(epoch)\n",
        "    evaluate( loaders[\"valid\"], model, 'cuda')\n"
      ],
      "metadata": {
        "id": "0thQZtJUZG7g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**ResNet152**"
      ],
      "metadata": {
        "id": "55whcwLnZP4h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install timm\n",
        "!CUDA_LAUNCH_BLOCKING=1\n",
        "import os\n",
        "import cv2\n",
        "import sys\n",
        "import json\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from functools import partial\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "from torch import nn\n",
        "from timm.utils import accuracy\n",
        "from timm.data import Mixup\n",
        "from timm.models import create_model\n",
        "from timm.loss import LabelSmoothingCrossEntropy, SoftTargetCrossEntropy\n",
        "from timm.scheduler import create_scheduler\n",
        "import torchvision.transforms as transforms\n",
        "from timm.optim import create_optimizer\n",
        "from timm.utils import NativeScaler, get_state_dict, ModelEma\n",
        "from timm.models.registry import register_model\n",
        "from timm.models.mlp_mixer import ResBlock, Affine, _create_mixer, _cfg\n",
        "from timm.models import create_model, resnet\n",
        "from timm.models.resnet import BasicBlock, Bottleneck, ResNet, _create_resnet\n",
        "import torchvision\n",
        "import numpy as np\n",
        "import collections\n",
        "import math\n",
        "from datetime import datetime\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive/', force_remount=True)\n",
        "\n",
        "# Modify these code line by specifying the path of Train and Test data as well as the path for saving the model.\n",
        "TRAIN_PATH = \"/content/drive/MyDrive/Colab_Notebooks/ViT-Ear/EarVN/train/\"\n",
        "TEST_PATH = \"/content/drive/MyDrive/Colab_Notebooks/ViT-Ear/EarVN/val/\"\n",
        "MODEL_PATH = \"/content/drive/MyDrive/Colab_Notebooks/ViT-Ear/EarVN/model/resnet152.pth\"\n",
        "\n",
        "image_size = 224\n",
        "IMG_SIZE = 224\n",
        "BATCH_SIZE = 32\n",
        "LR = 2e-05\n",
        "GAMMA = 0.7\n",
        "N_EPOCHS = 20\n",
        "N_CLASSES = 20\n",
        "\n",
        "def get_loaders(batch_size = BATCH_SIZE, num_workers=2):\n",
        "  transforms_train = transforms.Compose(\n",
        "    [\n",
        "        transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
        "        transforms.RandomHorizontalFlip(p=0.3),\n",
        "        transforms.RandomVerticalFlip(p=0.3),\n",
        "        transforms.RandomResizedCrop(IMG_SIZE),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n",
        "    ])\n",
        "\n",
        "  transforms_valid = torchvision.transforms.Compose(\n",
        "      [\n",
        "          transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
        "          transforms.ToTensor(),\n",
        "          transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n",
        "      ]\n",
        "  )\n",
        "\n",
        "  train_dataset = torchvision.datasets.ImageFolder(TRAIN_PATH, transform = transforms_train)\n",
        "  valid_dataset = torchvision.datasets.ImageFolder(TEST_PATH, transform = transforms_valid)\n",
        "\n",
        "  train_loader = torch.utils.data.DataLoader(\n",
        "      train_dataset,\n",
        "      batch_size=batch_size,\n",
        "      shuffle=True,\n",
        "      num_workers=num_workers,\n",
        "      drop_last=True,\n",
        "    )\n",
        "\n",
        "  valid_loader = torch.utils.data.DataLoader(\n",
        "      valid_dataset,\n",
        "      batch_size=batch_size,\n",
        "      shuffle=False,\n",
        "      num_workers=num_workers,\n",
        "      drop_last=True,\n",
        "    )\n",
        "\n",
        "  loaders = collections.OrderedDict()\n",
        "  loaders[\"train\"] = train_loader\n",
        "  loaders[\"valid\"] = valid_loader\n",
        "\n",
        "  return loaders\n",
        "\n",
        "@register_model\n",
        "def resnet152d(pretrained=False, **kwargs):\n",
        "  model_args = dict(block=Bottleneck, layers=[3, 8, 36, 3], stem_width=32, stem_type='deep', avg_down=True, **kwargs)\n",
        "  model = _create_resnet('resnet152d', pretrained, **model_args)\n",
        "  return model\n",
        "\n",
        "model = create_model(\n",
        "    'resnet152d',\n",
        "    pretrained=True,\n",
        "    num_classes=20)\n",
        "\n",
        "model_ema = ModelEma(\n",
        "    model,\n",
        "    decay=0.99,\n",
        "    device='cuda'\n",
        ")\n",
        "\n",
        "n_parameters = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "print('number of params:', n_parameters)\n",
        "\n",
        "linear_scaled_lr = 0.0001 * BATCH_SIZE * 1 / 512.0\n",
        "lr = linear_scaled_lr\n",
        "optimizer  = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "loss_scaler = NativeScaler()\n",
        "\n",
        "lr_scheduler =torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, 0.001)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "mixup_fn = Mixup(\n",
        "            mixup_alpha=0.2, cutmix_alpha=0.03, \n",
        "            prob=0.8, switch_prob=0.3, mode= 'batch', num_classes=20)\n",
        "\n",
        "@torch.no_grad()\n",
        "def evaluate(data_loader, model, device):\n",
        "    criterion = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "\n",
        "    # switch to evaluation mode\n",
        "    model.eval()\n",
        "    acc1_mean = 0.0\n",
        "    acc5_mean = 0.0\n",
        "    Batch = len(data_loader)\n",
        "    print('Total Batch:', Batch)\n",
        "    \n",
        "    for images, target in data_loader:\n",
        "        images = images.to(device, non_blocking=True)\n",
        "        target = target.to(device, non_blocking=True)\n",
        "\n",
        "        # compute output\n",
        "        with torch.cuda.amp.autocast():\n",
        "            output = model(images)\n",
        "            loss = criterion(output, target)\n",
        "\n",
        "        acc1, acc5 = accuracy(output, target, topk=(1, 5))\n",
        "        acc1_mean+=acc1.item()\n",
        "        acc5_mean+=acc5.item()\n",
        "        \n",
        "\n",
        "        batch_size = images.shape[0]\n",
        "    print('* Acc@1 {:.3f} Acc@5 {:.3f} loss {:.3f}'\n",
        "          .format(acc1_mean/Batch, acc5_mean/Batch, loss.item()))\n",
        "    \n",
        "def train_one_epoch(model, criterion, data_loader, optimizer,\n",
        "                    device, epoch, loss_scaler, max_norm,\n",
        "                    model_ema, mixup_fn):\n",
        "\n",
        "    model.train()\n",
        "    model.to(device)\n",
        "    header = 'Epoch: [{}]'.format(epoch)\n",
        "    print_freq = 50\n",
        "    count = 0\n",
        "    Batch = len(data_loader)\n",
        "    print('Total Batch:', Batch)\n",
        "    loss_mean = 0.0\n",
        "    for samples, targets in data_loader:\n",
        "        count +=1\n",
        "        samples = samples.to(device, non_blocking=True)\n",
        "        targets = targets.to(device, non_blocking=True)\n",
        "\n",
        "        if mixup_fn is not None:\n",
        "            samples, _ = mixup_fn(samples, targets)\n",
        "        with torch.cuda.amp.autocast():\n",
        "            outputs = model(samples)\n",
        "            \n",
        "            loss = criterion(outputs, targets)\n",
        "\n",
        "        loss_value = loss.item()\n",
        "        loss_mean += loss_value \n",
        "\n",
        "        if not math.isfinite(loss_value):\n",
        "            print(\"Loss is {}, stopping training\".format(loss_value))\n",
        "            sys.exit(1)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # this attribute is added by timm on one optimizer (adahessian)\n",
        "        is_second_order = hasattr(optimizer, 'is_second_order') and optimizer.is_second_order\n",
        "        loss_scaler(loss, optimizer, clip_grad=max_norm,\n",
        "                    parameters=model.parameters(), create_graph=is_second_order)\n",
        "\n",
        "        torch.cuda.synchronize()\n",
        "        if model_ema is not None:\n",
        "            model_ema.update(model)\n",
        "\n",
        "        if count % print_freq == 0:\n",
        "            current_time = datetime.now().strftime(\"%H:%M:%S\")\n",
        "            print(f'{current_time}\\tEPOCH: [{epoch}/10] STEP: [{count}/{Batch}], LOSS: {loss_mean/50}')\n",
        "            loss_mean = 0.0\n",
        "    torch.save({'model': model.state_dict(),\n",
        "                'optimizer': optimizer.state_dict(),\n",
        "                'lr_scheduler': lr_scheduler.state_dict(),\n",
        "                'epoch': epoch,\n",
        "                'model_ema': get_state_dict(model_ema),\n",
        "                }, MODEL_PATH)\n",
        "\n",
        "loaders = get_loaders()\n",
        "\n",
        "print(\"Start training\")\n",
        "max_accuracy = 0.0\n",
        "for epoch in range(0, 19):\n",
        "\n",
        "    train_stats = train_one_epoch(\n",
        "        model, criterion, loaders[\"train\"],\n",
        "        optimizer, 'cuda', epoch, loss_scaler,\n",
        "        None, model_ema, mixup_fn\n",
        "    )\n",
        "\n",
        "    lr_scheduler.step(epoch)\n",
        "    evaluate( loaders[\"valid\"], model, 'cuda')"
      ],
      "metadata": {
        "id": "PZ92xBbrZSli"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**ResNeXt50**"
      ],
      "metadata": {
        "id": "rBVrbmdtZjwO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install timm\n",
        "!CUDA_LAUNCH_BLOCKING=1\n",
        "import os\n",
        "import cv2\n",
        "import sys\n",
        "import json\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from functools import partial\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "from torch import nn\n",
        "from timm.utils import accuracy\n",
        "from timm.data import Mixup\n",
        "from timm.models import create_model\n",
        "from timm.loss import LabelSmoothingCrossEntropy, SoftTargetCrossEntropy\n",
        "from timm.scheduler import create_scheduler\n",
        "import torchvision.transforms as transforms\n",
        "from timm.optim import create_optimizer\n",
        "from timm.utils import NativeScaler, get_state_dict, ModelEma\n",
        "from timm.models.registry import register_model\n",
        "from timm.models.mlp_mixer import ResBlock, Affine, _create_mixer, _cfg\n",
        "from timm.models import create_model, resnet\n",
        "from timm.models.resnet import BasicBlock, Bottleneck, ResNet, _create_resnet\n",
        "import torchvision\n",
        "import numpy as np\n",
        "import collections\n",
        "import math\n",
        "from datetime import datetime\n",
        "from google.colab import drive\n",
        "\n",
        "# Modify these code line by specifying the path of Train and Test data as well as the path for saving the model.\n",
        "TRAIN_PATH = \"/content/drive/MyDrive/Colab_Notebooks/ViT-Ear/EarVN/train/\"\n",
        "TEST_PATH = \"/content/drive/MyDrive/Colab_Notebooks/ViT-Ear/EarVN/val/\"\n",
        "MODEL_PATH = \"/content/drive/MyDrive/Colab_Notebooks/ViT-Ear/EarVN/model/resnext50.pth\"\n",
        "\n",
        "image_size = 224\n",
        "IMG_SIZE = 224\n",
        "BATCH_SIZE = 32\n",
        "LR = 2e-05\n",
        "GAMMA = 0.7\n",
        "N_EPOCHS = 20\n",
        "N_CLASSES = 20\n",
        "\n",
        "def get_loaders(batch_size = BATCH_SIZE, num_workers=2):\n",
        "  transforms_train = transforms.Compose(\n",
        "    [\n",
        "        transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
        "        transforms.RandomHorizontalFlip(p=0.3),\n",
        "        transforms.RandomVerticalFlip(p=0.3),\n",
        "        transforms.RandomResizedCrop(IMG_SIZE),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n",
        "    ])\n",
        "\n",
        "  transforms_valid = torchvision.transforms.Compose(\n",
        "      [\n",
        "          transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
        "          transforms.ToTensor(),\n",
        "          transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n",
        "      ]\n",
        "  )\n",
        "\n",
        "  train_dataset = torchvision.datasets.ImageFolder(TRAIN_PATH, transform = transforms_train)\n",
        "  valid_dataset = torchvision.datasets.ImageFolder(TEST_PATH, transform = transforms_valid)\n",
        "\n",
        "  train_loader = torch.utils.data.DataLoader(\n",
        "      train_dataset,\n",
        "      batch_size=batch_size,\n",
        "      shuffle=True,\n",
        "      num_workers=num_workers,\n",
        "      drop_last=True,\n",
        "    )\n",
        "\n",
        "  valid_loader = torch.utils.data.DataLoader(\n",
        "      valid_dataset,\n",
        "      batch_size=batch_size,\n",
        "      shuffle=False,\n",
        "      num_workers=num_workers,\n",
        "      drop_last=True,\n",
        "    )\n",
        "\n",
        "  loaders = collections.OrderedDict()\n",
        "  loaders[\"train\"] = train_loader\n",
        "  loaders[\"valid\"] = valid_loader\n",
        "\n",
        "  return loaders\n",
        "\n",
        "@register_model\n",
        "def resnext50_32x4d(pretrained=False, **kwargs):\n",
        "  \"\"\"Constructs a ResNeXt50-32x4d model.\n",
        "  \"\"\"\n",
        "  model_args = dict(block=Bottleneck, layers=[3, 4, 6, 3], cardinality=32, base_width=4, **kwargs)\n",
        "  model = _create_resnet('resnext50_32x4d', pretrained, **model_args)\n",
        "  return model\n",
        "\n",
        "model = create_model(\n",
        "    'resnext50_32x4d',\n",
        "    pretrained=True,\n",
        "    num_classes=20)\n",
        "\n",
        "model_ema = ModelEma(\n",
        "    model,\n",
        "    decay=0.99,\n",
        "    device='cuda'\n",
        ")\n",
        "\n",
        "n_parameters = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "print('number of params:', n_parameters)\n",
        "\n",
        "linear_scaled_lr = 0.0001 * BATCH_SIZE * 1 / 512.0\n",
        "lr = linear_scaled_lr\n",
        "optimizer  = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "loss_scaler = NativeScaler()\n",
        "\n",
        "lr_scheduler =torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, 0.001)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "mixup_fn = Mixup(\n",
        "            mixup_alpha=0.2, cutmix_alpha=0.03, \n",
        "            prob=0.8, switch_prob=0.3, mode= 'batch', num_classes=20)\n",
        "\n",
        "@torch.no_grad()\n",
        "def evaluate(data_loader, model, device):\n",
        "    criterion = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "\n",
        "    # switch to evaluation mode\n",
        "    model.eval()\n",
        "    acc1_mean = 0.0\n",
        "    acc5_mean = 0.0\n",
        "    Batch = len(data_loader)\n",
        "    print('Total Batch:', Batch)\n",
        "    \n",
        "    for images, target in data_loader:\n",
        "        images = images.to(device, non_blocking=True)\n",
        "        target = target.to(device, non_blocking=True)\n",
        "\n",
        "        # compute output\n",
        "        with torch.cuda.amp.autocast():\n",
        "            output = model(images)\n",
        "            loss = criterion(output, target)\n",
        "\n",
        "        acc1, acc5 = accuracy(output, target, topk=(1, 5))\n",
        "        acc1_mean+=acc1.item()\n",
        "        acc5_mean+=acc5.item()\n",
        "        \n",
        "\n",
        "        batch_size = images.shape[0]\n",
        "    print('* Acc@1 {:.3f} Acc@5 {:.3f} loss {:.3f}'\n",
        "          .format(acc1_mean/Batch, acc5_mean/Batch, loss.item()))\n",
        "    \n",
        "def train_one_epoch(model, criterion, data_loader, optimizer,\n",
        "                    device, epoch, loss_scaler, max_norm,\n",
        "                    model_ema, mixup_fn):\n",
        "\n",
        "    model.train()\n",
        "    model.to(device)\n",
        "    header = 'Epoch: [{}]'.format(epoch)\n",
        "    print_freq = 50\n",
        "    count = 0\n",
        "    Batch = len(data_loader)\n",
        "    print('Total Batch:', Batch)\n",
        "    loss_mean = 0.0\n",
        "    for samples, targets in data_loader:\n",
        "        count +=1\n",
        "        samples = samples.to(device, non_blocking=True)\n",
        "        targets = targets.to(device, non_blocking=True)\n",
        "\n",
        "        if mixup_fn is not None:\n",
        "            samples, _ = mixup_fn(samples, targets)\n",
        "        with torch.cuda.amp.autocast():\n",
        "            outputs = model(samples)\n",
        "            \n",
        "            loss = criterion(outputs, targets)\n",
        "\n",
        "        loss_value = loss.item()\n",
        "        loss_mean += loss_value \n",
        "\n",
        "        if not math.isfinite(loss_value):\n",
        "            print(\"Loss is {}, stopping training\".format(loss_value))\n",
        "            sys.exit(1)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # this attribute is added by timm on one optimizer (adahessian)\n",
        "        is_second_order = hasattr(optimizer, 'is_second_order') and optimizer.is_second_order\n",
        "        loss_scaler(loss, optimizer, clip_grad=max_norm,\n",
        "                    parameters=model.parameters(), create_graph=is_second_order)\n",
        "\n",
        "        torch.cuda.synchronize()\n",
        "        if model_ema is not None:\n",
        "            model_ema.update(model)\n",
        "\n",
        "        if count % print_freq == 0:\n",
        "            current_time = datetime.now().strftime(\"%H:%M:%S\")\n",
        "            print(f'{current_time}\\tEPOCH: [{epoch}/10] STEP: [{count}/{Batch}], LOSS: {loss_mean/50}')\n",
        "            loss_mean = 0.0\n",
        "    torch.save({'model': model.state_dict(),\n",
        "                'optimizer': optimizer.state_dict(),\n",
        "                'lr_scheduler': lr_scheduler.state_dict(),\n",
        "                'epoch': epoch,\n",
        "                'model_ema': get_state_dict(model_ema),\n",
        "                }, MODEL_PATH)\n",
        "\n",
        "loaders = get_loaders()\n",
        "\n",
        "print(\"Start training\")\n",
        "max_accuracy = 0.0\n",
        "for epoch in range(0, 19):\n",
        "\n",
        "    train_stats = train_one_epoch(\n",
        "        model, criterion, loaders[\"train\"],\n",
        "        optimizer, 'cuda', epoch, loss_scaler,\n",
        "        None, model_ema, mixup_fn\n",
        "    )\n",
        "\n",
        "    lr_scheduler.step(epoch)\n",
        "    evaluate( loaders[\"valid\"], model, 'cuda')"
      ],
      "metadata": {
        "id": "loBHZPT1Zonr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**ViT**"
      ],
      "metadata": {
        "id": "51vZ0ErMZzQU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install timm\n",
        "!CUDA_LAUNCH_BLOCKING=1\n",
        "import os\n",
        "import cv2\n",
        "import sys\n",
        "import json\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from functools import partial\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "from torch import nn\n",
        "from timm.utils import accuracy\n",
        "from timm.data import Mixup\n",
        "from timm.models import create_model\n",
        "from timm.loss import LabelSmoothingCrossEntropy, SoftTargetCrossEntropy\n",
        "from timm.scheduler import create_scheduler\n",
        "import torchvision.transforms as transforms\n",
        "from timm.optim import create_optimizer\n",
        "from timm.utils import NativeScaler, get_state_dict, ModelEma\n",
        "from timm.models.registry import register_model\n",
        "from timm.models import create_model, vision_transformer\n",
        "from timm.models.vision_transformer import Attention, Block, VisionTransformer, _create_vision_transformer, _cfg\n",
        "import torchvision\n",
        "import numpy as np\n",
        "import collections\n",
        "import math\n",
        "from datetime import datetime\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive/', force_remount=True)\n",
        "\n",
        "# Modify these code line by specifying the path of Train and Test data as well as the path for saving the model.\n",
        "TRAIN_PATH = \"/content/drive/MyDrive/Colab_Notebooks/ViT-Ear/EarVN/train/\"\n",
        "TEST_PATH = \"/content/drive/MyDrive/Colab_Notebooks/ViT-Ear/EarVN/val/\"\n",
        "MODEL_PATH = \"/content/drive/MyDrive/Colab_Notebooks/ViT-Ear/EarVN/model/vit_p16.pth\"\n",
        "\n",
        "image_size = 224\n",
        "IMG_SIZE = 224\n",
        "BATCH_SIZE = 32\n",
        "LR = 2e-05\n",
        "GAMMA = 0.7\n",
        "N_EPOCHS = 20\n",
        "N_CLASSES = 20\n",
        "\n",
        "def get_loaders(batch_size = BATCH_SIZE, num_workers=2):\n",
        "  transforms_train = transforms.Compose(\n",
        "    [\n",
        "        transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
        "        transforms.RandomHorizontalFlip(p=0.3),\n",
        "        transforms.RandomVerticalFlip(p=0.3),\n",
        "        transforms.RandomResizedCrop(IMG_SIZE),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n",
        "    ])\n",
        "\n",
        "  transforms_valid = torchvision.transforms.Compose(\n",
        "      [\n",
        "          transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
        "          transforms.ToTensor(),\n",
        "          transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n",
        "      ]\n",
        "  )\n",
        "\n",
        "  train_dataset = torchvision.datasets.ImageFolder(TRAIN_PATH, transform = transforms_train)\n",
        "  valid_dataset = torchvision.datasets.ImageFolder(TEST_PATH, transform = transforms_valid)\n",
        "\n",
        "  train_loader = torch.utils.data.DataLoader(\n",
        "      train_dataset,\n",
        "      batch_size=batch_size,\n",
        "      shuffle=True,\n",
        "      num_workers=num_workers,\n",
        "      drop_last=True,\n",
        "    )\n",
        "\n",
        "  valid_loader = torch.utils.data.DataLoader(\n",
        "      valid_dataset,\n",
        "      batch_size=batch_size,\n",
        "      shuffle=False,\n",
        "      num_workers=num_workers,\n",
        "      drop_last=True,\n",
        "    )\n",
        "\n",
        "  loaders = collections.OrderedDict()\n",
        "  loaders[\"train\"] = train_loader\n",
        "  loaders[\"valid\"] = valid_loader\n",
        "\n",
        "  return loaders\n",
        "\n",
        "@register_model\n",
        "def vit_base_patch16_224(pretrained=False, **kwargs):\n",
        "  \"\"\" ViT-Base (ViT-B/16) from original paper (https://arxiv.org/abs/2010.11929).\n",
        "  ImageNet-1k weights fine-tuned from in21k @ 224x224, source https://github.com/google-research/vision_transformer.\n",
        "  \"\"\"\n",
        "  model_kwargs = dict(patch_size=16, embed_dim=768, depth=12, num_heads=12, **kwargs)\n",
        "  model = _create_vision_transformer('vit_base_patch16_224', pretrained=pretrained, **model_kwargs)\n",
        "  return model\n",
        "\n",
        "\n",
        "model = create_model(\n",
        "    'vit_base_patch16_224',\n",
        "    pretrained=True,\n",
        "    num_classes=20)\n",
        "\n",
        "model_ema = ModelEma(\n",
        "    model,\n",
        "    decay=0.99,\n",
        "    device='cuda'\n",
        ")\n",
        "\n",
        "n_parameters = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "print('number of params:', n_parameters)\n",
        "\n",
        "linear_scaled_lr = 0.0001 * BATCH_SIZE * 1 / 512.0\n",
        "lr = linear_scaled_lr\n",
        "optimizer  = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "loss_scaler = NativeScaler()\n",
        "\n",
        "lr_scheduler =torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, 0.001)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "mixup_fn = Mixup(\n",
        "            mixup_alpha=0.2, cutmix_alpha=0.03, \n",
        "            prob=0.8, switch_prob=0.3, mode= 'batch', num_classes=20)\n",
        "\n",
        "@torch.no_grad()\n",
        "def evaluate(data_loader, model, device):\n",
        "    criterion = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "\n",
        "    # switch to evaluation mode\n",
        "    model.eval()\n",
        "    acc1_mean = 0.0\n",
        "    acc5_mean = 0.0\n",
        "    Batch = len(data_loader)\n",
        "    print('Total Batch:', Batch)\n",
        "    \n",
        "    for images, target in data_loader:\n",
        "        images = images.to(device, non_blocking=True)\n",
        "        target = target.to(device, non_blocking=True)\n",
        "\n",
        "        # compute output\n",
        "        with torch.cuda.amp.autocast():\n",
        "            output = model(images)\n",
        "            loss = criterion(output, target)\n",
        "\n",
        "        acc1, acc5 = accuracy(output, target, topk=(1, 5))\n",
        "        acc1_mean+=acc1.item()\n",
        "        acc5_mean+=acc5.item()\n",
        "        \n",
        "\n",
        "        batch_size = images.shape[0]\n",
        "    print('* Acc@1 {:.3f} Acc@5 {:.3f} loss {:.3f}'\n",
        "          .format(acc1_mean/Batch, acc5_mean/Batch, loss.item()))\n",
        "    \n",
        "def train_one_epoch(model, criterion, data_loader, optimizer,\n",
        "                    device, epoch, loss_scaler, max_norm,\n",
        "                    model_ema, mixup_fn):\n",
        "\n",
        "    model.train()\n",
        "    model.to(device)\n",
        "    header = 'Epoch: [{}]'.format(epoch)\n",
        "    print_freq = 50\n",
        "    count = 0\n",
        "    Batch = len(data_loader)\n",
        "    print('Total Batch:', Batch)\n",
        "    loss_mean = 0.0\n",
        "    for samples, targets in data_loader:\n",
        "        count +=1\n",
        "        samples = samples.to(device, non_blocking=True)\n",
        "        targets = targets.to(device, non_blocking=True)\n",
        "\n",
        "        if mixup_fn is not None:\n",
        "            samples, _ = mixup_fn(samples, targets)\n",
        "        with torch.cuda.amp.autocast():\n",
        "            outputs = model(samples)\n",
        "            \n",
        "            loss = criterion(outputs, targets)\n",
        "\n",
        "        loss_value = loss.item()\n",
        "        loss_mean += loss_value \n",
        "\n",
        "        if not math.isfinite(loss_value):\n",
        "            print(\"Loss is {}, stopping training\".format(loss_value))\n",
        "            sys.exit(1)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # this attribute is added by timm on one optimizer (adahessian)\n",
        "        is_second_order = hasattr(optimizer, 'is_second_order') and optimizer.is_second_order\n",
        "        loss_scaler(loss, optimizer, clip_grad=max_norm,\n",
        "                    parameters=model.parameters(), create_graph=is_second_order)\n",
        "\n",
        "        torch.cuda.synchronize()\n",
        "        if model_ema is not None:\n",
        "            model_ema.update(model)\n",
        "\n",
        "        if count % print_freq == 0:\n",
        "            current_time = datetime.now().strftime(\"%H:%M:%S\")\n",
        "            print(f'{current_time}\\tEPOCH: [{epoch}/10] STEP: [{count}/{Batch}], LOSS: {loss_mean/50}')\n",
        "            loss_mean = 0.0\n",
        "    torch.save({'model': model.state_dict(),\n",
        "                'optimizer': optimizer.state_dict(),\n",
        "                'lr_scheduler': lr_scheduler.state_dict(),\n",
        "                'epoch': epoch,\n",
        "                'model_ema': get_state_dict(model_ema),\n",
        "                }, MODEL_PATH)\n",
        "\n",
        "loaders = get_loaders()\n",
        "\n",
        "print(\"Start training\")\n",
        "max_accuracy = 0.0\n",
        "for epoch in range(0, 19):\n",
        "\n",
        "    train_stats = train_one_epoch(\n",
        "        model, criterion, loaders[\"train\"],\n",
        "        optimizer, 'cuda', epoch, loss_scaler,\n",
        "        None, model_ema, mixup_fn\n",
        "    )\n",
        "\n",
        "    lr_scheduler.step(epoch)\n",
        "    evaluate( loaders[\"valid\"], model, 'cuda')"
      ],
      "metadata": {
        "id": "pcRs8hddZ0tF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**DeiT**"
      ],
      "metadata": {
        "id": "wJPVCv-kaOd-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install timm\n",
        "!CUDA_LAUNCH_BLOCKING=1\n",
        "import os\n",
        "import cv2\n",
        "import sys\n",
        "import json\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from functools import partial\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "from torch import nn\n",
        "from timm.utils import accuracy\n",
        "from timm.data import Mixup\n",
        "from timm.models import create_model\n",
        "from timm.loss import LabelSmoothingCrossEntropy, SoftTargetCrossEntropy\n",
        "from timm.scheduler import create_scheduler\n",
        "import torchvision.transforms as transforms\n",
        "from timm.optim import create_optimizer\n",
        "from timm.utils import NativeScaler, get_state_dict, ModelEma\n",
        "from timm.models.registry import register_model\n",
        "from timm.models import create_model, vision_transformer\n",
        "from timm.models.vision_transformer import Attention, Block, VisionTransformer, _create_vision_transformer, _cfg\n",
        "import torchvision\n",
        "import numpy as np\n",
        "import collections\n",
        "import math\n",
        "from datetime import datetime\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive/', force_remount=True)\n",
        "\n",
        "# Modify these code line by specifying the path of Train and Test data as well as the path for saving the model.\n",
        "TRAIN_PATH = \"/content/drive/MyDrive/Colab_Notebooks/ViT-Ear/EarVN/train/\"\n",
        "TEST_PATH = \"/content/drive/MyDrive/Colab_Notebooks/ViT-Ear/EarVN/val/\"\n",
        "MODEL_PATH = \"/content/drive/MyDrive/Colab_Notebooks/ViT-Ear/EarVN/model/deit_p16.pth\"\n",
        "\n",
        "image_size = 224\n",
        "IMG_SIZE = 224\n",
        "BATCH_SIZE = 32\n",
        "LR = 2e-05\n",
        "GAMMA = 0.7\n",
        "N_EPOCHS = 20\n",
        "N_CLASSES = 20\n",
        "\n",
        "def get_loaders(batch_size = BATCH_SIZE, num_workers=2):\n",
        "  transforms_train = transforms.Compose(\n",
        "    [\n",
        "        transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
        "        transforms.RandomHorizontalFlip(p=0.3),\n",
        "        transforms.RandomVerticalFlip(p=0.3),\n",
        "        transforms.RandomResizedCrop(IMG_SIZE),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n",
        "    ])\n",
        "\n",
        "  transforms_valid = torchvision.transforms.Compose(\n",
        "      [\n",
        "          transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
        "          transforms.ToTensor(),\n",
        "          transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n",
        "      ]\n",
        "  )\n",
        "\n",
        "  train_dataset = torchvision.datasets.ImageFolder(TRAIN_PATH, transform = transforms_train)\n",
        "  valid_dataset = torchvision.datasets.ImageFolder(TEST_PATH, transform = transforms_valid)\n",
        "\n",
        "  train_loader = torch.utils.data.DataLoader(\n",
        "      train_dataset,\n",
        "      batch_size=batch_size,\n",
        "      shuffle=True,\n",
        "      num_workers=num_workers,\n",
        "      drop_last=True,\n",
        "    )\n",
        "\n",
        "  valid_loader = torch.utils.data.DataLoader(\n",
        "      valid_dataset,\n",
        "      batch_size=batch_size,\n",
        "      shuffle=False,\n",
        "      num_workers=num_workers,\n",
        "      drop_last=True,\n",
        "    )\n",
        "\n",
        "  loaders = collections.OrderedDict()\n",
        "  loaders[\"train\"] = train_loader\n",
        "  loaders[\"valid\"] = valid_loader\n",
        "\n",
        "  return loaders\n",
        "\n",
        "@register_model\n",
        "def deit_base_patch16_224(pretrained=False, **kwargs):\n",
        "  \"\"\" DeiT base model @ 224x224 from paper (https://arxiv.org/abs/2012.12877).\n",
        "  ImageNet-1k weights from https://github.com/facebookresearch/deit.\n",
        "  \"\"\"\n",
        "  model_kwargs = dict(patch_size=16, embed_dim=768, depth=12, num_heads=12, **kwargs)\n",
        "  model = _create_vision_transformer('deit_base_patch16_224', pretrained=pretrained, **model_kwargs)\n",
        "  return model\n",
        "\n",
        "\n",
        "model = create_model(\n",
        "    'deit_base_patch16_224',\n",
        "    pretrained=True,\n",
        "    num_classes=20)\n",
        "\n",
        "model_ema = ModelEma(\n",
        "    model,\n",
        "    decay=0.99,\n",
        "    device='cuda'\n",
        ")\n",
        "\n",
        "n_parameters = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "print('number of params:', n_parameters)\n",
        "\n",
        "linear_scaled_lr = 0.0001 * BATCH_SIZE * 1 / 512.0\n",
        "lr = linear_scaled_lr\n",
        "optimizer  = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "loss_scaler = NativeScaler()\n",
        "\n",
        "lr_scheduler =torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, 0.001)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "mixup_fn = Mixup(\n",
        "            mixup_alpha=0.2, cutmix_alpha=0.03, \n",
        "            prob=0.8, switch_prob=0.3, mode= 'batch', num_classes=20)\n",
        "\n",
        "@torch.no_grad()\n",
        "def evaluate(data_loader, model, device):\n",
        "    criterion = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "\n",
        "    # switch to evaluation mode\n",
        "    model.eval()\n",
        "    acc1_mean = 0.0\n",
        "    acc5_mean = 0.0\n",
        "    Batch = len(data_loader)\n",
        "    print('Total Batch:', Batch)\n",
        "    \n",
        "    for images, target in data_loader:\n",
        "        images = images.to(device, non_blocking=True)\n",
        "        target = target.to(device, non_blocking=True)\n",
        "\n",
        "        # compute output\n",
        "        with torch.cuda.amp.autocast():\n",
        "            output = model(images)\n",
        "            loss = criterion(output, target)\n",
        "\n",
        "        acc1, acc5 = accuracy(output, target, topk=(1, 5))\n",
        "        acc1_mean+=acc1.item()\n",
        "        acc5_mean+=acc5.item()\n",
        "        \n",
        "\n",
        "        batch_size = images.shape[0]\n",
        "    print('* Acc@1 {:.3f} Acc@5 {:.3f} loss {:.3f}'\n",
        "          .format(acc1_mean/Batch, acc5_mean/Batch, loss.item()))\n",
        "    \n",
        "def train_one_epoch(model, criterion, data_loader, optimizer,\n",
        "                    device, epoch, loss_scaler, max_norm,\n",
        "                    model_ema, mixup_fn):\n",
        "\n",
        "    model.train()\n",
        "    model.to(device)\n",
        "    header = 'Epoch: [{}]'.format(epoch)\n",
        "    print_freq = 50\n",
        "    count = 0\n",
        "    Batch = len(data_loader)\n",
        "    print('Total Batch:', Batch)\n",
        "    loss_mean = 0.0\n",
        "    for samples, targets in data_loader:\n",
        "        count +=1\n",
        "        samples = samples.to(device, non_blocking=True)\n",
        "        targets = targets.to(device, non_blocking=True)\n",
        "\n",
        "        if mixup_fn is not None:\n",
        "            samples, _ = mixup_fn(samples, targets)\n",
        "        with torch.cuda.amp.autocast():\n",
        "            outputs = model(samples)\n",
        "            \n",
        "            loss = criterion(outputs, targets)\n",
        "\n",
        "        loss_value = loss.item()\n",
        "        loss_mean += loss_value \n",
        "\n",
        "        if not math.isfinite(loss_value):\n",
        "            print(\"Loss is {}, stopping training\".format(loss_value))\n",
        "            sys.exit(1)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # this attribute is added by timm on one optimizer (adahessian)\n",
        "        is_second_order = hasattr(optimizer, 'is_second_order') and optimizer.is_second_order\n",
        "        loss_scaler(loss, optimizer, clip_grad=max_norm,\n",
        "                    parameters=model.parameters(), create_graph=is_second_order)\n",
        "\n",
        "        torch.cuda.synchronize()\n",
        "        if model_ema is not None:\n",
        "            model_ema.update(model)\n",
        "\n",
        "        if count % print_freq == 0:\n",
        "            current_time = datetime.now().strftime(\"%H:%M:%S\")\n",
        "            print(f'{current_time}\\tEPOCH: [{epoch}/10] STEP: [{count}/{Batch}], LOSS: {loss_mean/50}')\n",
        "            loss_mean = 0.0\n",
        "    torch.save({'model': model.state_dict(),\n",
        "                'optimizer': optimizer.state_dict(),\n",
        "                'lr_scheduler': lr_scheduler.state_dict(),\n",
        "                'epoch': epoch,\n",
        "                'model_ema': get_state_dict(model_ema),\n",
        "                }, MODEL_PATH)\n",
        "\n",
        "loaders = get_loaders()\n",
        "\n",
        "print(\"Start training\")\n",
        "max_accuracy = 0.0\n",
        "for epoch in range(0, 19):\n",
        "\n",
        "    train_stats = train_one_epoch(\n",
        "        model, criterion, loaders[\"train\"],\n",
        "        optimizer, 'cuda', epoch, loss_scaler,\n",
        "        None, model_ema, mixup_fn\n",
        "    )\n",
        "\n",
        "    lr_scheduler.step(epoch)\n",
        "    evaluate( loaders[\"valid\"], model, 'cuda')"
      ],
      "metadata": {
        "id": "0b14s-4saOvd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**CaiT**"
      ],
      "metadata": {
        "id": "c3GOou3laYeG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install timm\n",
        "!CUDA_LAUNCH_BLOCKING=1\n",
        "import os\n",
        "import cv2\n",
        "import sys\n",
        "import json\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from functools import partial\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "from torch import nn\n",
        "from timm.utils import accuracy\n",
        "from timm.data import Mixup\n",
        "from timm.models import create_model\n",
        "from timm.loss import LabelSmoothingCrossEntropy, SoftTargetCrossEntropy\n",
        "from timm.scheduler import create_scheduler\n",
        "import torchvision.transforms as transforms\n",
        "from timm.optim import create_optimizer\n",
        "from timm.utils import NativeScaler, get_state_dict, ModelEma\n",
        "from timm.models.registry import register_model\n",
        "from timm.models import create_model, cait\n",
        "from timm.models.cait import ClassAttn, LayerScaleBlockClassAttn, TalkingHeadAttn, LayerScaleBlock, Cait, _cfg, _create_cait\n",
        "import torchvision\n",
        "import numpy as np\n",
        "import collections\n",
        "import math\n",
        "from datetime import datetime\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive/', force_remount=True)\n",
        "\n",
        "# Modify these code line by specifying the path of Train and Test data as well as the path for saving the model.\n",
        "TRAIN_PATH = \"/content/drive/MyDrive/Colab_Notebooks/ViT-Ear/EarVN/train/\"\n",
        "TEST_PATH = \"/content/drive/MyDrive/Colab_Notebooks/ViT-Ear/EarVN/val/\"\n",
        "MODEL_PATH = \"/content/drive/MyDrive/Colab_Notebooks/ViT-Ear/EarVN/model/cait24.pth\"\n",
        "\n",
        "image_size = 224\n",
        "IMG_SIZE = 224\n",
        "BATCH_SIZE = 32\n",
        "LR = 2e-05\n",
        "GAMMA = 0.7\n",
        "N_EPOCHS = 20\n",
        "N_CLASSES = 20\n",
        "\n",
        "def get_loaders(batch_size = BATCH_SIZE, num_workers=2):\n",
        "  transforms_train = transforms.Compose(\n",
        "    [\n",
        "        transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
        "        transforms.RandomHorizontalFlip(p=0.3),\n",
        "        transforms.RandomVerticalFlip(p=0.3),\n",
        "        transforms.RandomResizedCrop(IMG_SIZE),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n",
        "    ])\n",
        "\n",
        "  transforms_valid = torchvision.transforms.Compose(\n",
        "      [\n",
        "          transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
        "          transforms.ToTensor(),\n",
        "          transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n",
        "      ]\n",
        "  )\n",
        "\n",
        "  train_dataset = torchvision.datasets.ImageFolder(TRAIN_PATH, transform = transforms_train)\n",
        "  valid_dataset = torchvision.datasets.ImageFolder(TEST_PATH, transform = transforms_valid)\n",
        "\n",
        "  train_loader = torch.utils.data.DataLoader(\n",
        "      train_dataset,\n",
        "      batch_size=batch_size,\n",
        "      shuffle=True,\n",
        "      num_workers=num_workers,\n",
        "      drop_last=True,\n",
        "    )\n",
        "\n",
        "  valid_loader = torch.utils.data.DataLoader(\n",
        "      valid_dataset,\n",
        "      batch_size=batch_size,\n",
        "      shuffle=False,\n",
        "      num_workers=num_workers,\n",
        "      drop_last=True,\n",
        "    )\n",
        "\n",
        "  loaders = collections.OrderedDict()\n",
        "  loaders[\"train\"] = train_loader\n",
        "  loaders[\"valid\"] = valid_loader\n",
        "\n",
        "  return loaders\n",
        "\n",
        "@register_model\n",
        "def cait_xxs24_224(pretrained=False, **kwargs):\n",
        "  model_args = dict(patch_size=16, embed_dim=192, depth=24, num_heads=4, init_scale=1e-5, **kwargs)\n",
        "  model = _create_cait('cait_xxs24_224', pretrained=pretrained, **model_args)\n",
        "  return model\n",
        "\n",
        "model = create_model(\n",
        "    'cait_xxs24_224',\n",
        "    pretrained=True,\n",
        "    num_classes=20)\n",
        "\n",
        "model_ema = ModelEma(\n",
        "    model,\n",
        "    decay=0.99,\n",
        "    device='cuda'\n",
        ")\n",
        "\n",
        "n_parameters = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "print('number of params:', n_parameters)\n",
        "\n",
        "linear_scaled_lr = 0.0001 * BATCH_SIZE * 1 / 512.0\n",
        "lr = linear_scaled_lr\n",
        "optimizer  = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "loss_scaler = NativeScaler()\n",
        "\n",
        "lr_scheduler =torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, 0.001)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "mixup_fn = Mixup(\n",
        "            mixup_alpha=0.2, cutmix_alpha=0.03, \n",
        "            prob=0.8, switch_prob=0.3, mode= 'batch', num_classes=20)\n",
        "\n",
        "@torch.no_grad()\n",
        "def evaluate(data_loader, model, device):\n",
        "    criterion = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "\n",
        "    # switch to evaluation mode\n",
        "    model.eval()\n",
        "    acc1_mean = 0.0\n",
        "    acc5_mean = 0.0\n",
        "    Batch = len(data_loader)\n",
        "    print('Total Batch:', Batch)\n",
        "    \n",
        "    for images, target in data_loader:\n",
        "        images = images.to(device, non_blocking=True)\n",
        "        target = target.to(device, non_blocking=True)\n",
        "\n",
        "        # compute output\n",
        "        with torch.cuda.amp.autocast():\n",
        "            output = model(images)\n",
        "            loss = criterion(output, target)\n",
        "\n",
        "        acc1, acc5 = accuracy(output, target, topk=(1, 5))\n",
        "        acc1_mean+=acc1.item()\n",
        "        acc5_mean+=acc5.item()\n",
        "        \n",
        "\n",
        "        batch_size = images.shape[0]\n",
        "    print('* Acc@1 {:.3f} Acc@5 {:.3f} loss {:.3f}'\n",
        "          .format(acc1_mean/Batch, acc5_mean/Batch, loss.item()))\n",
        "    \n",
        "def train_one_epoch(model, criterion, data_loader, optimizer,\n",
        "                    device, epoch, loss_scaler, max_norm,\n",
        "                    model_ema, mixup_fn):\n",
        "\n",
        "    model.train()\n",
        "    model.to(device)\n",
        "    header = 'Epoch: [{}]'.format(epoch)\n",
        "    print_freq = 50\n",
        "    count = 0\n",
        "    Batch = len(data_loader)\n",
        "    print('Total Batch:', Batch)\n",
        "    loss_mean = 0.0\n",
        "    for samples, targets in data_loader:\n",
        "        count +=1\n",
        "        samples = samples.to(device, non_blocking=True)\n",
        "        targets = targets.to(device, non_blocking=True)\n",
        "\n",
        "        if mixup_fn is not None:\n",
        "            samples, _ = mixup_fn(samples, targets)\n",
        "        with torch.cuda.amp.autocast():\n",
        "            outputs = model(samples)\n",
        "            \n",
        "            loss = criterion(outputs, targets)\n",
        "\n",
        "        loss_value = loss.item()\n",
        "        loss_mean += loss_value \n",
        "\n",
        "        if not math.isfinite(loss_value):\n",
        "            print(\"Loss is {}, stopping training\".format(loss_value))\n",
        "            sys.exit(1)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # this attribute is added by timm on one optimizer (adahessian)\n",
        "        is_second_order = hasattr(optimizer, 'is_second_order') and optimizer.is_second_order\n",
        "        loss_scaler(loss, optimizer, clip_grad=max_norm,\n",
        "                    parameters=model.parameters(), create_graph=is_second_order)\n",
        "\n",
        "        torch.cuda.synchronize()\n",
        "        if model_ema is not None:\n",
        "            model_ema.update(model)\n",
        "\n",
        "        if count % print_freq == 0:\n",
        "            current_time = datetime.now().strftime(\"%H:%M:%S\")\n",
        "            print(f'{current_time}\\tEPOCH: [{epoch}/10] STEP: [{count}/{Batch}], LOSS: {loss_mean/50}')\n",
        "            loss_mean = 0.0\n",
        "    torch.save({'model': model.state_dict(),\n",
        "                'optimizer': optimizer.state_dict(),\n",
        "                'lr_scheduler': lr_scheduler.state_dict(),\n",
        "                'epoch': epoch,\n",
        "                'model_ema': get_state_dict(model_ema),\n",
        "                }, MODEL_PATH)\n",
        "\n",
        "loaders = get_loaders()\n",
        "\n",
        "print(\"Start training\")\n",
        "max_accuracy = 0.0\n",
        "for epoch in range(0, 19):\n",
        "\n",
        "    train_stats = train_one_epoch(\n",
        "        model, criterion, loaders[\"train\"],\n",
        "        optimizer, 'cuda', epoch, loss_scaler,\n",
        "        None, model_ema, mixup_fn\n",
        "    )\n",
        "\n",
        "    lr_scheduler.step(epoch)\n",
        "    evaluate( loaders[\"valid\"], model, 'cuda')"
      ],
      "metadata": {
        "id": "rcQseYKMaYvO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**ConViT**"
      ],
      "metadata": {
        "id": "NaY7E8XGar66"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install timm\n",
        "!CUDA_LAUNCH_BLOCKING=1\n",
        "import os\n",
        "import cv2\n",
        "import sys\n",
        "import json\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from functools import partial\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "from torch import nn\n",
        "from timm.utils import accuracy\n",
        "from timm.data import Mixup\n",
        "from timm.models import create_model\n",
        "from timm.loss import LabelSmoothingCrossEntropy, SoftTargetCrossEntropy\n",
        "from timm.scheduler import create_scheduler\n",
        "import torchvision.transforms as transforms\n",
        "from timm.optim import create_optimizer\n",
        "from timm.utils import NativeScaler, get_state_dict, ModelEma\n",
        "from timm.models.registry import register_model\n",
        "from timm.models import create_model, convit\n",
        "from timm.models.convit import GPSA, MHSA, Block, ConViT, _create_convit, _cfg\n",
        "import torchvision\n",
        "import numpy as np\n",
        "import collections\n",
        "import math\n",
        "from datetime import datetime\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive/', force_remount=True)\n",
        "\n",
        "# Modify these code line by specifying the path of Train and Test data as well as the path for saving the model.\n",
        "TRAIN_PATH = \"/content/drive/MyDrive/Colab_Notebooks/ViT-Ear/EarVN/train/\"\n",
        "TEST_PATH = \"/content/drive/MyDrive/Colab_Notebooks/ViT-Ear/EarVN/val/\"\n",
        "MODEL_PATH = \"/content/drive/MyDrive/Colab_Notebooks/ViT-Ear/EarVN/model/convit24.pth\"\n",
        "\n",
        "image_size = 224\n",
        "IMG_SIZE = 224\n",
        "BATCH_SIZE = 32\n",
        "LR = 2e-05\n",
        "GAMMA = 0.7\n",
        "N_EPOCHS = 20\n",
        "N_CLASSES = 20\n",
        "\n",
        "def get_loaders(batch_size = BATCH_SIZE, num_workers=2):\n",
        "  transforms_train = transforms.Compose(\n",
        "    [\n",
        "        transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
        "        transforms.RandomHorizontalFlip(p=0.3),\n",
        "        transforms.RandomVerticalFlip(p=0.3),\n",
        "        transforms.RandomResizedCrop(IMG_SIZE),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n",
        "    ])\n",
        "\n",
        "  transforms_valid = torchvision.transforms.Compose(\n",
        "      [\n",
        "          transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
        "          transforms.ToTensor(),\n",
        "          transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n",
        "      ]\n",
        "  )\n",
        "\n",
        "  train_dataset = torchvision.datasets.ImageFolder(TRAIN_PATH, transform = transforms_train)\n",
        "  valid_dataset = torchvision.datasets.ImageFolder(TEST_PATH, transform = transforms_valid)\n",
        "\n",
        "  train_loader = torch.utils.data.DataLoader(\n",
        "      train_dataset,\n",
        "      batch_size=batch_size,\n",
        "      shuffle=True,\n",
        "      num_workers=num_workers,\n",
        "      drop_last=True,\n",
        "    )\n",
        "\n",
        "  valid_loader = torch.utils.data.DataLoader(\n",
        "      valid_dataset,\n",
        "      batch_size=batch_size,\n",
        "      shuffle=False,\n",
        "      num_workers=num_workers,\n",
        "      drop_last=True,\n",
        "    )\n",
        "\n",
        "  loaders = collections.OrderedDict()\n",
        "  loaders[\"train\"] = train_loader\n",
        "  loaders[\"valid\"] = valid_loader\n",
        "\n",
        "  return loaders\n",
        "\n",
        "@register_model\n",
        "def convit_base(pretrained=False, **kwargs):\n",
        "  model_args = dict(\n",
        "      local_up_to_layer=10, locality_strength=1.0, embed_dim=48,\n",
        "      num_heads=16, norm_layer=partial(nn.LayerNorm, eps=1e-6), **kwargs)\n",
        "  model = _create_convit(variant='convit_base', pretrained=pretrained, **model_args)\n",
        "  return model\n",
        "\n",
        "\n",
        "model = create_model(\n",
        "    'convit_base',\n",
        "    pretrained=True,\n",
        "    num_classes=20)\n",
        "\n",
        "model_ema = ModelEma(\n",
        "    model,\n",
        "    decay=0.99,\n",
        "    device='cuda'\n",
        ")\n",
        "\n",
        "n_parameters = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "print('number of params:', n_parameters)\n",
        "\n",
        "linear_scaled_lr = 0.0001 * BATCH_SIZE * 1 / 512.0\n",
        "lr = linear_scaled_lr\n",
        "optimizer  = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "loss_scaler = NativeScaler()\n",
        "\n",
        "lr_scheduler =torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, 0.001)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "mixup_fn = Mixup(\n",
        "            mixup_alpha=0.2, cutmix_alpha=0.03, \n",
        "            prob=0.8, switch_prob=0.3, mode= 'batch', num_classes=20)\n",
        "\n",
        "@torch.no_grad()\n",
        "def evaluate(data_loader, model, device):\n",
        "    criterion = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "\n",
        "    # switch to evaluation mode\n",
        "    model.eval()\n",
        "    acc1_mean = 0.0\n",
        "    acc5_mean = 0.0\n",
        "    Batch = len(data_loader)\n",
        "    print('Total Batch:', Batch)\n",
        "    \n",
        "    for images, target in data_loader:\n",
        "        images = images.to(device, non_blocking=True)\n",
        "        target = target.to(device, non_blocking=True)\n",
        "\n",
        "        # compute output\n",
        "        with torch.cuda.amp.autocast():\n",
        "            output = model(images)\n",
        "            loss = criterion(output, target)\n",
        "\n",
        "        acc1, acc5 = accuracy(output, target, topk=(1, 5))\n",
        "        acc1_mean+=acc1.item()\n",
        "        acc5_mean+=acc5.item()\n",
        "        \n",
        "\n",
        "        batch_size = images.shape[0]\n",
        "    print('* Acc@1 {:.3f} Acc@5 {:.3f} loss {:.3f}'\n",
        "          .format(acc1_mean/Batch, acc5_mean/Batch, loss.item()))\n",
        "    \n",
        "def train_one_epoch(model, criterion, data_loader, optimizer,\n",
        "                    device, epoch, loss_scaler, max_norm,\n",
        "                    model_ema, mixup_fn):\n",
        "\n",
        "    model.train()\n",
        "    model.to(device)\n",
        "    header = 'Epoch: [{}]'.format(epoch)\n",
        "    print_freq = 50\n",
        "    count = 0\n",
        "    Batch = len(data_loader)\n",
        "    print('Total Batch:', Batch)\n",
        "    loss_mean = 0.0\n",
        "    for samples, targets in data_loader:\n",
        "        count +=1\n",
        "        samples = samples.to(device, non_blocking=True)\n",
        "        targets = targets.to(device, non_blocking=True)\n",
        "\n",
        "        if mixup_fn is not None:\n",
        "            samples, _ = mixup_fn(samples, targets)\n",
        "        with torch.cuda.amp.autocast():\n",
        "            outputs = model(samples)\n",
        "            \n",
        "            loss = criterion(outputs, targets)\n",
        "\n",
        "        loss_value = loss.item()\n",
        "        loss_mean += loss_value \n",
        "\n",
        "        if not math.isfinite(loss_value):\n",
        "            print(\"Loss is {}, stopping training\".format(loss_value))\n",
        "            sys.exit(1)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # this attribute is added by timm on one optimizer (adahessian)\n",
        "        is_second_order = hasattr(optimizer, 'is_second_order') and optimizer.is_second_order\n",
        "        loss_scaler(loss, optimizer, clip_grad=max_norm,\n",
        "                    parameters=model.parameters(), create_graph=is_second_order)\n",
        "\n",
        "        torch.cuda.synchronize()\n",
        "        if model_ema is not None:\n",
        "            model_ema.update(model)\n",
        "\n",
        "        if count % print_freq == 0:\n",
        "            current_time = datetime.now().strftime(\"%H:%M:%S\")\n",
        "            print(f'{current_time}\\tEPOCH: [{epoch}/10] STEP: [{count}/{Batch}], LOSS: {loss_mean/50}')\n",
        "            loss_mean = 0.0\n",
        "    torch.save({'model': model.state_dict(),\n",
        "                'optimizer': optimizer.state_dict(),\n",
        "                'lr_scheduler': lr_scheduler.state_dict(),\n",
        "                'epoch': epoch,\n",
        "                'model_ema': get_state_dict(model_ema),\n",
        "                }, MODEL_PATH)\n",
        "\n",
        "loaders = get_loaders()\n",
        "\n",
        "print(\"Start training\")\n",
        "max_accuracy = 0.0\n",
        "for epoch in range(0, 19):\n",
        "\n",
        "    train_stats = train_one_epoch(\n",
        "        model, criterion, loaders[\"train\"],\n",
        "        optimizer, 'cuda', epoch, loss_scaler,\n",
        "        None, model_ema, mixup_fn\n",
        "    )\n",
        "\n",
        "    lr_scheduler.step(epoch)\n",
        "    evaluate( loaders[\"valid\"], model, 'cuda')"
      ],
      "metadata": {
        "id": "JuuraFkcasL1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**CrossViT**"
      ],
      "metadata": {
        "id": "rz0Yaa5ba9cL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install git+https://github.com/rwightman/pytorch-image-models.git\n",
        "!CUDA_LAUNCH_BLOCKING=1\n",
        "import os\n",
        "import cv2\n",
        "import sys\n",
        "import json\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from functools import partial\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "from torch import nn\n",
        "from timm.utils import accuracy\n",
        "from timm.data import Mixup\n",
        "from timm.models import create_model\n",
        "from timm.loss import LabelSmoothingCrossEntropy, SoftTargetCrossEntropy\n",
        "from timm.scheduler import create_scheduler\n",
        "import torchvision.transforms as transforms\n",
        "from timm.optim import create_optimizer\n",
        "from timm.utils import NativeScaler, get_state_dict, ModelEma\n",
        "from timm.models.registry import register_model\n",
        "from timm.models import create_model\n",
        "from timm.models.crossvit import PatchEmbed, CrossAttention, CrossAttentionBlock, MultiScaleBlock, _compute_num_patches, CrossViT, _create_crossvit,_cfg\n",
        "import torchvision\n",
        "import numpy as np\n",
        "import collections\n",
        "import math\n",
        "from datetime import datetime\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive/', force_remount=True)\n",
        "\n",
        "# Modify these code line by specifying the path of Train and Test data as well as the path for saving the model.\n",
        "TRAIN_PATH = \"/content/drive/MyDrive/Colab_Notebooks/ViT-Ear/EarVN/train/\"\n",
        "TEST_PATH = \"/content/drive/MyDrive/Colab_Notebooks/ViT-Ear/EarVN/val/\"\n",
        "MODEL_PATH = \"/content/drive/MyDrive/Colab_Notebooks/ViT-Ear/EarVN/model/crossvit.pth\"\n",
        "\n",
        "image_size = 240\n",
        "IMG_SIZE = 240\n",
        "BATCH_SIZE = 32\n",
        "LR = 2e-05\n",
        "GAMMA = 0.7\n",
        "N_EPOCHS = 20\n",
        "N_CLASSES = 20\n",
        "\n",
        "def get_loaders(batch_size = BATCH_SIZE, num_workers=2):\n",
        "  transforms_train = transforms.Compose(\n",
        "    [\n",
        "        transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
        "        transforms.RandomHorizontalFlip(p=0.3),\n",
        "        transforms.RandomVerticalFlip(p=0.3),\n",
        "        transforms.RandomResizedCrop(IMG_SIZE),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n",
        "    ])\n",
        "\n",
        "  transforms_valid = torchvision.transforms.Compose(\n",
        "      [\n",
        "          transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
        "          transforms.ToTensor(),\n",
        "          transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n",
        "      ]\n",
        "  )\n",
        "\n",
        "  train_dataset = torchvision.datasets.ImageFolder(TRAIN_PATH, transform = transforms_train)\n",
        "  valid_dataset = torchvision.datasets.ImageFolder(TEST_PATH, transform = transforms_valid)\n",
        "\n",
        "  train_loader = torch.utils.data.DataLoader(\n",
        "      train_dataset,\n",
        "      batch_size=batch_size,\n",
        "      shuffle=True,\n",
        "      num_workers=num_workers,\n",
        "      drop_last=True,\n",
        "    )\n",
        "\n",
        "  valid_loader = torch.utils.data.DataLoader(\n",
        "      valid_dataset,\n",
        "      batch_size=batch_size,\n",
        "      shuffle=False,\n",
        "      num_workers=num_workers,\n",
        "      drop_last=True,\n",
        "    )\n",
        "\n",
        "  loaders = collections.OrderedDict()\n",
        "  loaders[\"train\"] = train_loader\n",
        "  loaders[\"valid\"] = valid_loader\n",
        "\n",
        "  return loaders\n",
        "\n",
        "@register_model\n",
        "def crossvit_base_240(pretrained=False, **kwargs):\n",
        "  model_args = dict(\n",
        "      img_scale=(1.0, 224/240), patch_size=[12, 16], embed_dim=[384, 768], depth=[[1, 4, 0], [1, 4, 0], [1, 4, 0]],\n",
        "      num_heads=[12, 12], mlp_ratio=[4, 4, 1], **kwargs)\n",
        "  model = _create_crossvit(variant='crossvit_base_240', pretrained=pretrained, **model_args)\n",
        "  return model\n",
        "\n",
        "model = create_model(\n",
        "    'crossvit_base_240',\n",
        "    pretrained=True,\n",
        "    num_classes=20)\n",
        "\n",
        "model_ema = ModelEma(\n",
        "    model,\n",
        "    decay=0.99,\n",
        "    device='cuda'\n",
        ")\n",
        "\n",
        "n_parameters = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "print('number of params:', n_parameters)\n",
        "\n",
        "linear_scaled_lr = 0.0001 * BATCH_SIZE * 1 / 512.0\n",
        "lr = linear_scaled_lr\n",
        "optimizer  = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "loss_scaler = NativeScaler()\n",
        "\n",
        "lr_scheduler =torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, 0.001)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "mixup_fn = Mixup(\n",
        "            mixup_alpha=0.2, cutmix_alpha=0.03, \n",
        "            prob=0.8, switch_prob=0.3, mode= 'batch', num_classes=20)\n",
        "\n",
        "@torch.no_grad()\n",
        "def evaluate(data_loader, model, device):\n",
        "    criterion = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "\n",
        "    # switch to evaluation mode\n",
        "    model.eval()\n",
        "    acc1_mean = 0.0\n",
        "    acc5_mean = 0.0\n",
        "    Batch = len(data_loader)\n",
        "    print('Total Batch:', Batch)\n",
        "    \n",
        "    for images, target in data_loader:\n",
        "        images = images.to(device, non_blocking=True)\n",
        "        target = target.to(device, non_blocking=True)\n",
        "\n",
        "        # compute output\n",
        "        with torch.cuda.amp.autocast():\n",
        "            output = model(images)\n",
        "            loss = criterion(output, target)\n",
        "\n",
        "        acc1, acc5 = accuracy(output, target, topk=(1, 5))\n",
        "        acc1_mean+=acc1.item()\n",
        "        acc5_mean+=acc5.item()\n",
        "        \n",
        "\n",
        "        batch_size = images.shape[0]\n",
        "    print('* Acc@1 {:.3f} Acc@5 {:.3f} loss {:.3f}'\n",
        "          .format(acc1_mean/Batch, acc5_mean/Batch, loss.item()))\n",
        "    \n",
        "def train_one_epoch(model, criterion, data_loader, optimizer,\n",
        "                    device, epoch, loss_scaler, max_norm,\n",
        "                    model_ema, mixup_fn):\n",
        "\n",
        "    model.train()\n",
        "    model.to(device)\n",
        "    header = 'Epoch: [{}]'.format(epoch)\n",
        "    print_freq = 50\n",
        "    count = 0\n",
        "    Batch = len(data_loader)\n",
        "    print('Total Batch:', Batch)\n",
        "    loss_mean = 0.0\n",
        "    for samples, targets in data_loader:\n",
        "        count +=1\n",
        "        samples = samples.to(device, non_blocking=True)\n",
        "        targets = targets.to(device, non_blocking=True)\n",
        "\n",
        "        if mixup_fn is not None:\n",
        "            samples, _ = mixup_fn(samples, targets)\n",
        "        with torch.cuda.amp.autocast():\n",
        "            outputs = model(samples)\n",
        "            \n",
        "            loss = criterion(outputs, targets)\n",
        "\n",
        "        loss_value = loss.item()\n",
        "        loss_mean += loss_value \n",
        "\n",
        "        if not math.isfinite(loss_value):\n",
        "            print(\"Loss is {}, stopping training\".format(loss_value))\n",
        "            sys.exit(1)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # this attribute is added by timm on one optimizer (adahessian)\n",
        "        is_second_order = hasattr(optimizer, 'is_second_order') and optimizer.is_second_order\n",
        "        loss_scaler(loss, optimizer, clip_grad=max_norm,\n",
        "                    parameters=model.parameters(), create_graph=is_second_order)\n",
        "\n",
        "        torch.cuda.synchronize()\n",
        "        if model_ema is not None:\n",
        "            model_ema.update(model)\n",
        "\n",
        "        if count % print_freq == 0:\n",
        "            current_time = datetime.now().strftime(\"%H:%M:%S\")\n",
        "            print(f'{current_time}\\tEPOCH: [{epoch}/10] STEP: [{count}/{Batch}], LOSS: {loss_mean/50}')\n",
        "            loss_mean = 0.0\n",
        "    torch.save({'model': model.state_dict(),\n",
        "                'optimizer': optimizer.state_dict(),\n",
        "                'lr_scheduler': lr_scheduler.state_dict(),\n",
        "                'epoch': epoch,\n",
        "                'model_ema': get_state_dict(model_ema),\n",
        "                }, MODEL_PATH)\n",
        "\n",
        "loaders = get_loaders()\n",
        "\n",
        "print(\"Start training\")\n",
        "max_accuracy = 0.0\n",
        "for epoch in range(0, 19):\n",
        "\n",
        "    train_stats = train_one_epoch(\n",
        "        model, criterion, loaders[\"train\"],\n",
        "        optimizer, 'cuda', epoch, loss_scaler,\n",
        "        None, model_ema, mixup_fn\n",
        "    )\n",
        "\n",
        "    lr_scheduler.step(epoch)\n",
        "    evaluate( loaders[\"valid\"], model, 'cuda')"
      ],
      "metadata": {
        "id": "cP6HGb8CbAjV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Swin Transformer**"
      ],
      "metadata": {
        "id": "T9cL-3yHbIuM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install git+https://github.com/rwightman/pytorch-image-models.git\n",
        "!CUDA_LAUNCH_BLOCKING=1\n",
        "import os\n",
        "import cv2\n",
        "import sys\n",
        "import json\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from functools import partial\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "from torch import nn\n",
        "from timm.utils import accuracy\n",
        "from timm.data import Mixup\n",
        "from timm.models import create_model\n",
        "from timm.loss import LabelSmoothingCrossEntropy, SoftTargetCrossEntropy\n",
        "from timm.scheduler import create_scheduler\n",
        "import torchvision.transforms as transforms\n",
        "from timm.optim import create_optimizer\n",
        "from timm.utils import NativeScaler, get_state_dict, ModelEma\n",
        "from timm.models.registry import register_model\n",
        "from timm.models import create_model\n",
        "from timm.models.swin_transformer import window_partition, WindowAttention, SwinTransformerBlock, PatchMerging, BasicLayer, SwinTransformer, _create_swin_transformer, _cfg\n",
        "import torchvision\n",
        "import numpy as np\n",
        "import collections\n",
        "import math\n",
        "from datetime import datetime\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive/', force_remount=True)\n",
        "\n",
        "# Modify these code line by specifying the path of Train and Test data as well as the path for saving the model.\n",
        "TRAIN_PATH = \"/content/drive/MyDrive/Colab_Notebooks/ViT-Ear/EarVN/train/\"\n",
        "TEST_PATH = \"/content/drive/MyDrive/Colab_Notebooks/ViT-Ear/EarVN/val/\"\n",
        "MODEL_PATH = \"/content/drive/MyDrive/Colab_Notebooks/ViT-Ear/EarVN/model/SwinT.pth\"\n",
        "\n",
        "image_size = 224\n",
        "IMG_SIZE = 224\n",
        "BATCH_SIZE = 32\n",
        "LR = 2e-05\n",
        "GAMMA = 0.7\n",
        "N_EPOCHS = 20\n",
        "N_CLASSES = 20\n",
        "\n",
        "def get_loaders(batch_size = BATCH_SIZE, num_workers=2):\n",
        "  transforms_train = transforms.Compose(\n",
        "    [\n",
        "        transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
        "        transforms.RandomHorizontalFlip(p=0.3),\n",
        "        transforms.RandomVerticalFlip(p=0.3),\n",
        "        transforms.RandomResizedCrop(IMG_SIZE),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n",
        "    ])\n",
        "\n",
        "  transforms_valid = torchvision.transforms.Compose(\n",
        "      [\n",
        "          transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
        "          transforms.ToTensor(),\n",
        "          transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n",
        "      ]\n",
        "  )\n",
        "\n",
        "  train_dataset = torchvision.datasets.ImageFolder(TRAIN_PATH, transform = transforms_train)\n",
        "  valid_dataset = torchvision.datasets.ImageFolder(TEST_PATH, transform = transforms_valid)\n",
        "\n",
        "  train_loader = torch.utils.data.DataLoader(\n",
        "      train_dataset,\n",
        "      batch_size=batch_size,\n",
        "      shuffle=True,\n",
        "      num_workers=num_workers,\n",
        "      drop_last=True,\n",
        "    )\n",
        "\n",
        "  valid_loader = torch.utils.data.DataLoader(\n",
        "      valid_dataset,\n",
        "      batch_size=batch_size,\n",
        "      shuffle=False,\n",
        "      num_workers=num_workers,\n",
        "      drop_last=True,\n",
        "    )\n",
        "\n",
        "  loaders = collections.OrderedDict()\n",
        "  loaders[\"train\"] = train_loader\n",
        "  loaders[\"valid\"] = valid_loader\n",
        "\n",
        "  return loaders\n",
        "\n",
        "@register_model\n",
        "def swin_base_patch4_window7_224(pretrained=False, **kwargs):\n",
        "  \"\"\" Swin-B @ 224x224, pretrained ImageNet-22k, fine tune 1k\n",
        "  \"\"\"\n",
        "  model_kwargs = dict(\n",
        "      patch_size=4, window_size=7, embed_dim=128, depths=(2, 2, 18, 2), num_heads=(4, 8, 16, 32), **kwargs)\n",
        "  return _create_swin_transformer('swin_base_patch4_window7_224', pretrained=pretrained, **model_kwargs)\n",
        "\n",
        "model = create_model(\n",
        "    'swin_base_patch4_window7_224',\n",
        "    pretrained=True,\n",
        "    num_classes=20)\n",
        "\n",
        "model_ema = ModelEma(\n",
        "    model,\n",
        "    decay=0.99,\n",
        "    device='cuda'\n",
        ")\n",
        "\n",
        "n_parameters = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "print('number of params:', n_parameters)\n",
        "\n",
        "linear_scaled_lr = 0.0001 * BATCH_SIZE * 1 / 512.0\n",
        "lr = linear_scaled_lr\n",
        "optimizer  = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "loss_scaler = NativeScaler()\n",
        "\n",
        "lr_scheduler =torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, 0.001)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "mixup_fn = Mixup(\n",
        "            mixup_alpha=0.2, cutmix_alpha=0.03, \n",
        "            prob=0.8, switch_prob=0.3, mode= 'batch', num_classes=20)\n",
        "\n",
        "@torch.no_grad()\n",
        "def evaluate(data_loader, model, device):\n",
        "    criterion = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "\n",
        "    # switch to evaluation mode\n",
        "    model.eval()\n",
        "    acc1_mean = 0.0\n",
        "    acc5_mean = 0.0\n",
        "    Batch = len(data_loader)\n",
        "    print('Total Batch:', Batch)\n",
        "    \n",
        "    for images, target in data_loader:\n",
        "        images = images.to(device, non_blocking=True)\n",
        "        target = target.to(device, non_blocking=True)\n",
        "\n",
        "        # compute output\n",
        "        with torch.cuda.amp.autocast():\n",
        "            output = model(images)\n",
        "            loss = criterion(output, target)\n",
        "\n",
        "        acc1, acc5 = accuracy(output, target, topk=(1, 5))\n",
        "        acc1_mean+=acc1.item()\n",
        "        acc5_mean+=acc5.item()\n",
        "        \n",
        "\n",
        "        batch_size = images.shape[0]\n",
        "    print('* Acc@1 {:.3f} Acc@5 {:.3f} loss {:.3f}'\n",
        "          .format(acc1_mean/Batch, acc5_mean/Batch, loss.item()))\n",
        "    \n",
        "def train_one_epoch(model, criterion, data_loader, optimizer,\n",
        "                    device, epoch, loss_scaler, max_norm,\n",
        "                    model_ema, mixup_fn):\n",
        "\n",
        "    model.train()\n",
        "    model.to(device)\n",
        "    header = 'Epoch: [{}]'.format(epoch)\n",
        "    print_freq = 50\n",
        "    count = 0\n",
        "    Batch = len(data_loader)\n",
        "    print('Total Batch:', Batch)\n",
        "    loss_mean = 0.0\n",
        "    for samples, targets in data_loader:\n",
        "        count +=1\n",
        "        samples = samples.to(device, non_blocking=True)\n",
        "        targets = targets.to(device, non_blocking=True)\n",
        "\n",
        "        if mixup_fn is not None:\n",
        "            samples, _ = mixup_fn(samples, targets)\n",
        "        with torch.cuda.amp.autocast():\n",
        "            outputs = model(samples)\n",
        "            \n",
        "            loss = criterion(outputs, targets)\n",
        "\n",
        "        loss_value = loss.item()\n",
        "        loss_mean += loss_value \n",
        "\n",
        "        if not math.isfinite(loss_value):\n",
        "            print(\"Loss is {}, stopping training\".format(loss_value))\n",
        "            sys.exit(1)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # this attribute is added by timm on one optimizer (adahessian)\n",
        "        is_second_order = hasattr(optimizer, 'is_second_order') and optimizer.is_second_order\n",
        "        loss_scaler(loss, optimizer, clip_grad=max_norm,\n",
        "                    parameters=model.parameters(), create_graph=is_second_order)\n",
        "\n",
        "        torch.cuda.synchronize()\n",
        "        if model_ema is not None:\n",
        "            model_ema.update(model)\n",
        "\n",
        "        if count % print_freq == 0:\n",
        "            current_time = datetime.now().strftime(\"%H:%M:%S\")\n",
        "            print(f'{current_time}\\tEPOCH: [{epoch}/10] STEP: [{count}/{Batch}], LOSS: {loss_mean/50}')\n",
        "            loss_mean = 0.0\n",
        "    torch.save({'model': model.state_dict(),\n",
        "                'optimizer': optimizer.state_dict(),\n",
        "                'lr_scheduler': lr_scheduler.state_dict(),\n",
        "                'epoch': epoch,\n",
        "                'model_ema': get_state_dict(model_ema),\n",
        "                }, MODEL_PATH)\n",
        "\n",
        "loaders = get_loaders()\n",
        "\n",
        "print(\"Start training\")\n",
        "max_accuracy = 0.0\n",
        "for epoch in range(0, 19):\n",
        "\n",
        "    train_stats = train_one_epoch(\n",
        "        model, criterion, loaders[\"train\"],\n",
        "        optimizer, 'cuda', epoch, loss_scaler,\n",
        "        None, model_ema, mixup_fn\n",
        "    )\n",
        "\n",
        "    lr_scheduler.step(epoch)\n",
        "    evaluate( loaders[\"valid\"], model, 'cuda')"
      ],
      "metadata": {
        "id": "JseJh9LUbMpj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**XCiT**"
      ],
      "metadata": {
        "id": "qxoywUmBbShm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install git+https://github.com/rwightman/pytorch-image-models.git\n",
        "!CUDA_LAUNCH_BLOCKING=1\n",
        "import os\n",
        "import cv2\n",
        "import sys\n",
        "import json\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from functools import partial\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "from torch import nn\n",
        "from timm.utils import accuracy\n",
        "from timm.data import Mixup\n",
        "from timm.models import create_model\n",
        "from timm.loss import LabelSmoothingCrossEntropy, SoftTargetCrossEntropy\n",
        "from timm.scheduler import create_scheduler\n",
        "import torchvision.transforms as transforms\n",
        "from timm.optim import create_optimizer\n",
        "from timm.utils import NativeScaler, get_state_dict, ModelEma\n",
        "from timm.models.registry import register_model\n",
        "from timm.models import create_model\n",
        "from timm.models.xcit import PositionalEncodingFourier, ConvPatchEmbed, LPI, ClassAttentionBlock, XCA, XCABlock, XCiT, checkpoint_filter_fn, _create_xcit, _cfg\n",
        "import torchvision\n",
        "import numpy as np\n",
        "import collections\n",
        "import math\n",
        "from datetime import datetime\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive/', force_remount=True)\n",
        "\n",
        "# Modify these code line by specifying the path of Train and Test data as well as the path for saving the model.\n",
        "TRAIN_PATH = \"/content/drive/MyDrive/Colab_Notebooks/ViT-Ear/EarVN/train/\"\n",
        "TEST_PATH = \"/content/drive/MyDrive/Colab_Notebooks/ViT-Ear/EarVN/val/\"\n",
        "MODEL_PATH = \"/content/drive/MyDrive/Colab_Notebooks/ViT-Ear/EarVN/model/XCiT.pth\"\n",
        "\n",
        "image_size = 224\n",
        "IMG_SIZE = 224\n",
        "BATCH_SIZE = 32\n",
        "LR = 2e-05\n",
        "GAMMA = 0.7\n",
        "N_EPOCHS = 20\n",
        "N_CLASSES = 20\n",
        "\n",
        "def get_loaders(batch_size = BATCH_SIZE, num_workers=2):\n",
        "  transforms_train = transforms.Compose(\n",
        "    [\n",
        "        transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
        "        transforms.RandomHorizontalFlip(p=0.3),\n",
        "        transforms.RandomVerticalFlip(p=0.3),\n",
        "        transforms.RandomResizedCrop(IMG_SIZE),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n",
        "    ])\n",
        "\n",
        "  transforms_valid = torchvision.transforms.Compose(\n",
        "      [\n",
        "          transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
        "          transforms.ToTensor(),\n",
        "          transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n",
        "      ]\n",
        "  )\n",
        "\n",
        "  train_dataset = torchvision.datasets.ImageFolder(TRAIN_PATH, transform = transforms_train)\n",
        "  valid_dataset = torchvision.datasets.ImageFolder(TEST_PATH, transform = transforms_valid)\n",
        "\n",
        "  train_loader = torch.utils.data.DataLoader(\n",
        "      train_dataset,\n",
        "      batch_size=batch_size,\n",
        "      shuffle=True,\n",
        "      num_workers=num_workers,\n",
        "      drop_last=True,\n",
        "    )\n",
        "\n",
        "  valid_loader = torch.utils.data.DataLoader(\n",
        "      valid_dataset,\n",
        "      batch_size=batch_size,\n",
        "      shuffle=False,\n",
        "      num_workers=num_workers,\n",
        "      drop_last=True,\n",
        "    )\n",
        "\n",
        "  loaders = collections.OrderedDict()\n",
        "  loaders[\"train\"] = train_loader\n",
        "  loaders[\"valid\"] = valid_loader\n",
        "\n",
        "  return loaders\n",
        "\n",
        "@register_model\n",
        "def xcit_nano_12_p16_224(pretrained=False, **kwargs):\n",
        "  model_kwargs = dict(patch_size=16, embed_dim=128, depth=12, num_heads=4, eta=1.0, tokens_norm=False, **kwargs)\n",
        "  model = _create_xcit('xcit_nano_12_p16_224', pretrained=pretrained, **model_kwargs)\n",
        "  return model\n",
        "\n",
        "model = create_model(\n",
        "    'xcit_nano_12_p16_224',\n",
        "    pretrained=True,\n",
        "    num_classes=20)\n",
        "\n",
        "model_ema = ModelEma(\n",
        "    model,\n",
        "    decay=0.99,\n",
        "    device='cuda'\n",
        ")\n",
        "\n",
        "n_parameters = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "print('number of params:', n_parameters)\n",
        "\n",
        "linear_scaled_lr = 0.0001 * BATCH_SIZE * 1 / 512.0\n",
        "lr = linear_scaled_lr\n",
        "optimizer  = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "loss_scaler = NativeScaler()\n",
        "\n",
        "lr_scheduler =torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, 0.001)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "mixup_fn = Mixup(\n",
        "            mixup_alpha=0.2, cutmix_alpha=0.03, \n",
        "            prob=0.8, switch_prob=0.3, mode= 'batch', num_classes=20)\n",
        "\n",
        "@torch.no_grad()\n",
        "def evaluate(data_loader, model, device):\n",
        "    criterion = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "\n",
        "    # switch to evaluation mode\n",
        "    model.eval()\n",
        "    acc1_mean = 0.0\n",
        "    acc5_mean = 0.0\n",
        "    Batch = len(data_loader)\n",
        "    print('Total Batch:', Batch)\n",
        "    \n",
        "    for images, target in data_loader:\n",
        "        images = images.to(device, non_blocking=True)\n",
        "        target = target.to(device, non_blocking=True)\n",
        "\n",
        "        # compute output\n",
        "        with torch.cuda.amp.autocast():\n",
        "            output = model(images)\n",
        "            loss = criterion(output, target)\n",
        "\n",
        "        acc1, acc5 = accuracy(output, target, topk=(1, 5))\n",
        "        acc1_mean+=acc1.item()\n",
        "        acc5_mean+=acc5.item()\n",
        "        \n",
        "\n",
        "        batch_size = images.shape[0]\n",
        "    print('* Acc@1 {:.3f} Acc@5 {:.3f} loss {:.3f}'\n",
        "          .format(acc1_mean/Batch, acc5_mean/Batch, loss.item()))\n",
        "    \n",
        "def train_one_epoch(model, criterion, data_loader, optimizer,\n",
        "                    device, epoch, loss_scaler, max_norm,\n",
        "                    model_ema, mixup_fn):\n",
        "\n",
        "    model.train()\n",
        "    model.to(device)\n",
        "    header = 'Epoch: [{}]'.format(epoch)\n",
        "    print_freq = 50\n",
        "    count = 0\n",
        "    Batch = len(data_loader)\n",
        "    print('Total Batch:', Batch)\n",
        "    loss_mean = 0.0\n",
        "    for samples, targets in data_loader:\n",
        "        count +=1\n",
        "        samples = samples.to(device, non_blocking=True)\n",
        "        targets = targets.to(device, non_blocking=True)\n",
        "\n",
        "        if mixup_fn is not None:\n",
        "            samples, _ = mixup_fn(samples, targets)\n",
        "        with torch.cuda.amp.autocast():\n",
        "            outputs = model(samples)\n",
        "            \n",
        "            loss = criterion(outputs, targets)\n",
        "\n",
        "        loss_value = loss.item()\n",
        "        loss_mean += loss_value \n",
        "\n",
        "        if not math.isfinite(loss_value):\n",
        "            print(\"Loss is {}, stopping training\".format(loss_value))\n",
        "            sys.exit(1)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # this attribute is added by timm on one optimizer (adahessian)\n",
        "        is_second_order = hasattr(optimizer, 'is_second_order') and optimizer.is_second_order\n",
        "        loss_scaler(loss, optimizer, clip_grad=max_norm,\n",
        "                    parameters=model.parameters(), create_graph=is_second_order)\n",
        "\n",
        "        torch.cuda.synchronize()\n",
        "        if model_ema is not None:\n",
        "            model_ema.update(model)\n",
        "\n",
        "        if count % print_freq == 0:\n",
        "            current_time = datetime.now().strftime(\"%H:%M:%S\")\n",
        "            print(f'{current_time}\\tEPOCH: [{epoch}/10] STEP: [{count}/{Batch}], LOSS: {loss_mean/50}')\n",
        "            loss_mean = 0.0\n",
        "    torch.save({'model': model.state_dict(),\n",
        "                'optimizer': optimizer.state_dict(),\n",
        "                'lr_scheduler': lr_scheduler.state_dict(),\n",
        "                'epoch': epoch,\n",
        "                'model_ema': get_state_dict(model_ema),\n",
        "                }, MODEL_PATH)\n",
        "\n",
        "loaders = get_loaders()\n",
        "\n",
        "print(\"Start training\")\n",
        "max_accuracy = 0.0\n",
        "for epoch in range(0, 19):\n",
        "\n",
        "    train_stats = train_one_epoch(\n",
        "        model, criterion, loaders[\"train\"],\n",
        "        optimizer, 'cuda', epoch, loss_scaler,\n",
        "        None, model_ema, mixup_fn\n",
        "    )\n",
        "\n",
        "    lr_scheduler.step(epoch)\n",
        "    evaluate( loaders[\"valid\"], model, 'cuda')"
      ],
      "metadata": {
        "id": "6Pq9wfznbS1V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**PiT**"
      ],
      "metadata": {
        "id": "1JBk3dI6bpHk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install git+https://github.com/rwightman/pytorch-image-models.git\n",
        "!CUDA_LAUNCH_BLOCKING=1\n",
        "import os\n",
        "import cv2\n",
        "import sys\n",
        "import json\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from functools import partial\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "from torch import nn\n",
        "from timm.utils import accuracy\n",
        "from timm.data import Mixup\n",
        "from timm.models import create_model\n",
        "from timm.loss import LabelSmoothingCrossEntropy, SoftTargetCrossEntropy\n",
        "from timm.scheduler import create_scheduler\n",
        "import torchvision.transforms as transforms\n",
        "from timm.optim import create_optimizer\n",
        "from timm.utils import NativeScaler, get_state_dict, ModelEma\n",
        "from timm.models.registry import register_model\n",
        "from timm.models import create_model\n",
        "from timm.models.pit import SequentialTuple, Transformer, ConvHeadPooling, ConvEmbedding, PoolingVisionTransformer, checkpoint_filter_fn, _create_pit, _cfg\n",
        "import torchvision\n",
        "import numpy as np\n",
        "import collections\n",
        "import math\n",
        "from datetime import datetime\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive/', force_remount=True)\n",
        "\n",
        "# Modify these code line by specifying the path of Train and Test data as well as the path for saving the model.\n",
        "TRAIN_PATH = \"/content/drive/MyDrive/Colab_Notebooks/ViT-Ear/EarVN/train/\"\n",
        "TEST_PATH = \"/content/drive/MyDrive/Colab_Notebooks/ViT-Ear/EarVN/val/\"\n",
        "MODEL_PATH = \"/content/drive/MyDrive/Colab_Notebooks/ViT-Ear/EarVN/model/PiT.pth\"\n",
        "\n",
        "image_size = 224\n",
        "IMG_SIZE = 224\n",
        "BATCH_SIZE = 32\n",
        "LR = 2e-05\n",
        "GAMMA = 0.7\n",
        "N_EPOCHS = 20\n",
        "N_CLASSES = 20\n",
        "\n",
        "def get_loaders(batch_size = BATCH_SIZE, num_workers=2):\n",
        "  transforms_train = transforms.Compose(\n",
        "    [\n",
        "        transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
        "        transforms.RandomHorizontalFlip(p=0.3),\n",
        "        transforms.RandomVerticalFlip(p=0.3),\n",
        "        transforms.RandomResizedCrop(IMG_SIZE),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n",
        "    ])\n",
        "\n",
        "  transforms_valid = torchvision.transforms.Compose(\n",
        "      [\n",
        "          transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
        "          transforms.ToTensor(),\n",
        "          transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n",
        "      ]\n",
        "  )\n",
        "\n",
        "  train_dataset = torchvision.datasets.ImageFolder(TRAIN_PATH, transform = transforms_train)\n",
        "  valid_dataset = torchvision.datasets.ImageFolder(TEST_PATH, transform = transforms_valid)\n",
        "\n",
        "  train_loader = torch.utils.data.DataLoader(\n",
        "      train_dataset,\n",
        "      batch_size=batch_size,\n",
        "      shuffle=True,\n",
        "      num_workers=num_workers,\n",
        "      drop_last=True,\n",
        "    )\n",
        "\n",
        "  valid_loader = torch.utils.data.DataLoader(\n",
        "      valid_dataset,\n",
        "      batch_size=batch_size,\n",
        "      shuffle=False,\n",
        "      num_workers=num_workers,\n",
        "      drop_last=True,\n",
        "    )\n",
        "\n",
        "  loaders = collections.OrderedDict()\n",
        "  loaders[\"train\"] = train_loader\n",
        "  loaders[\"valid\"] = valid_loader\n",
        "\n",
        "  return loaders\n",
        "\n",
        "@register_model\n",
        "def pit_b_224(pretrained, **kwargs):\n",
        "  model_kwargs = dict(patch_size=14,stride=7,base_dims=[64, 64, 64], depth=[3, 6, 4],heads=[4, 8, 16],mlp_ratio=4,**kwargs)\n",
        "  model = _create_pit('pit_b_224', pretrained, **model_kwargs)\n",
        "  return model\n",
        "\n",
        "model = create_model(\n",
        "    'pit_b_224',\n",
        "    pretrained=True,\n",
        "    num_classes=20)\n",
        "\n",
        "model_ema = ModelEma(\n",
        "    model,\n",
        "    decay=0.99,\n",
        "    device='cuda')\n",
        "\n",
        "n_parameters = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "print('number of params:', n_parameters)\n",
        "\n",
        "linear_scaled_lr = 0.0001 * BATCH_SIZE * 1 / 512.0\n",
        "lr = linear_scaled_lr\n",
        "optimizer  = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "loss_scaler = NativeScaler()\n",
        "\n",
        "lr_scheduler =torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, 0.001)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "mixup_fn = Mixup(\n",
        "            mixup_alpha=0.2, cutmix_alpha=0.03, \n",
        "            prob=0.8, switch_prob=0.3, mode= 'batch', num_classes=20)\n",
        "\n",
        "@torch.no_grad()\n",
        "def evaluate(data_loader, model, device):\n",
        "    criterion = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "\n",
        "    # switch to evaluation mode\n",
        "    model.eval()\n",
        "    acc1_mean = 0.0\n",
        "    acc5_mean = 0.0\n",
        "    Batch = len(data_loader)\n",
        "    print('Total Batch:', Batch)\n",
        "    \n",
        "    for images, target in data_loader:\n",
        "        images = images.to(device, non_blocking=True)\n",
        "        target = target.to(device, non_blocking=True)\n",
        "\n",
        "        # compute output\n",
        "        with torch.cuda.amp.autocast():\n",
        "            output = model(images)\n",
        "            loss = criterion(output, target)\n",
        "\n",
        "        acc1, acc5 = accuracy(output, target, topk=(1, 5))\n",
        "        acc1_mean+=acc1.item()\n",
        "        acc5_mean+=acc5.item()\n",
        "        \n",
        "\n",
        "        batch_size = images.shape[0]\n",
        "    print('* Acc@1 {:.3f} Acc@5 {:.3f} loss {:.3f}'\n",
        "          .format(acc1_mean/Batch, acc5_mean/Batch, loss.item()))\n",
        "    \n",
        "def train_one_epoch(model, criterion, data_loader, optimizer,\n",
        "                    device, epoch, loss_scaler, max_norm,\n",
        "                    model_ema, mixup_fn):\n",
        "\n",
        "    model.train()\n",
        "    model.to(device)\n",
        "    header = 'Epoch: [{}]'.format(epoch)\n",
        "    print_freq = 50\n",
        "    count = 0\n",
        "    Batch = len(data_loader)\n",
        "    print('Total Batch:', Batch)\n",
        "    loss_mean = 0.0\n",
        "    for samples, targets in data_loader:\n",
        "        count +=1\n",
        "        samples = samples.to(device, non_blocking=True)\n",
        "        targets = targets.to(device, non_blocking=True)\n",
        "\n",
        "        if mixup_fn is not None:\n",
        "            samples, _ = mixup_fn(samples, targets)\n",
        "        with torch.cuda.amp.autocast():\n",
        "            outputs = model(samples)\n",
        "            \n",
        "            loss = criterion(outputs, targets)\n",
        "\n",
        "        loss_value = loss.item()\n",
        "        loss_mean += loss_value \n",
        "\n",
        "        if not math.isfinite(loss_value):\n",
        "            print(\"Loss is {}, stopping training\".format(loss_value))\n",
        "            sys.exit(1)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # this attribute is added by timm on one optimizer (adahessian)\n",
        "        is_second_order = hasattr(optimizer, 'is_second_order') and optimizer.is_second_order\n",
        "        loss_scaler(loss, optimizer, clip_grad=max_norm,\n",
        "                    parameters=model.parameters(), create_graph=is_second_order)\n",
        "\n",
        "        torch.cuda.synchronize()\n",
        "        if model_ema is not None:\n",
        "            model_ema.update(model)\n",
        "\n",
        "        if count % print_freq == 0:\n",
        "            current_time = datetime.now().strftime(\"%H:%M:%S\")\n",
        "            print(f'{current_time}\\tEPOCH: [{epoch}/10] STEP: [{count}/{Batch}], LOSS: {loss_mean/50}')\n",
        "            loss_mean = 0.0\n",
        "    torch.save({'model': model.state_dict(),\n",
        "                'optimizer': optimizer.state_dict(),\n",
        "                'lr_scheduler': lr_scheduler.state_dict(),\n",
        "                'epoch': epoch,\n",
        "                'model_ema': get_state_dict(model_ema),\n",
        "                }, MODEL_PATH)\n",
        "\n",
        "loaders = get_loaders()\n",
        "\n",
        "print(\"Start training\")\n",
        "max_accuracy = 0.0\n",
        "for epoch in range(0, 19):\n",
        "\n",
        "    train_stats = train_one_epoch(\n",
        "        model, criterion, loaders[\"train\"],\n",
        "        optimizer, 'cuda', epoch, loss_scaler,\n",
        "        None, model_ema, mixup_fn\n",
        "    )\n",
        "\n",
        "    lr_scheduler.step(epoch)\n",
        "    evaluate( loaders[\"valid\"], model, 'cuda')"
      ],
      "metadata": {
        "id": "BlTptmPQbpzu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**ResMLP12**"
      ],
      "metadata": {
        "id": "rDShnBrCVXxY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vqr1Y9yFU0eI"
      },
      "outputs": [],
      "source": [
        "!pip install timm\n",
        "!CUDA_LAUNCH_BLOCKING=1\n",
        "import os\n",
        "import cv2\n",
        "import sys\n",
        "import json\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from functools import partial\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "from torch import nn\n",
        "from timm.utils import accuracy\n",
        "from timm.data import Mixup\n",
        "from timm.models import create_model\n",
        "from timm.loss import LabelSmoothingCrossEntropy, SoftTargetCrossEntropy\n",
        "from timm.scheduler import create_scheduler\n",
        "import torchvision.transforms as transforms\n",
        "from timm.optim import create_optimizer\n",
        "from timm.utils import NativeScaler, get_state_dict, ModelEma\n",
        "from timm.models.registry import register_model\n",
        "from timm.models.mlp_mixer import ResBlock, Affine, _create_mixer, _cfg\n",
        "from timm.models import create_model\n",
        "import torchvision\n",
        "import numpy as np\n",
        "import collections\n",
        "import math\n",
        "from datetime import datetime\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive/', force_remount=True)\n",
        "\n",
        "# Modify these code line by specifying the path of Train and Test data as well as the path for saving the model.\n",
        "TRAIN_PATH = \"/content/drive/Shareddrives/vit-ear/ViT-Ear/EarVN/train/\"\n",
        "TEST_PATH = \"/content/drive/Shareddrives/vit-ear/ViT-Ear/EarVN/val/\"\n",
        "MODEL_PATH = \"/content/drive/Shareddrives/vit-ear/ViT-Ear/EarVN/model/resmlp12.pth\"\n",
        "\n",
        "image_size = 224\n",
        "IMG_SIZE = 224\n",
        "BATCH_SIZE = 32\n",
        "LR = 2e-05\n",
        "GAMMA = 0.7\n",
        "N_EPOCHS = 20\n",
        "N_CLASSES = 20\n",
        "\n",
        "def get_loaders(batch_size = BATCH_SIZE, num_workers=2):\n",
        "  transforms_train = transforms.Compose(\n",
        "    [\n",
        "        transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
        "        transforms.RandomHorizontalFlip(p=0.3),\n",
        "        transforms.RandomVerticalFlip(p=0.3),\n",
        "        transforms.RandomResizedCrop(IMG_SIZE),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n",
        "    ])\n",
        "\n",
        "  transforms_valid = torchvision.transforms.Compose(\n",
        "      [\n",
        "          transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
        "          transforms.ToTensor(),\n",
        "          transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n",
        "      ]\n",
        "  )\n",
        "\n",
        "  train_dataset = torchvision.datasets.ImageFolder(TRAIN_PATH, transform = transforms_train)\n",
        "  valid_dataset = torchvision.datasets.ImageFolder(TEST_PATH, transform = transforms_valid)\n",
        "\n",
        "  train_loader = torch.utils.data.DataLoader(\n",
        "      train_dataset,\n",
        "      batch_size=batch_size,\n",
        "      shuffle=True,\n",
        "      num_workers=num_workers,\n",
        "      drop_last=True,\n",
        "    )\n",
        "\n",
        "  valid_loader = torch.utils.data.DataLoader(\n",
        "      valid_dataset,\n",
        "      batch_size=batch_size,\n",
        "      shuffle=False,\n",
        "      num_workers=num_workers,\n",
        "      drop_last=True,\n",
        "    )\n",
        "\n",
        "  loaders = collections.OrderedDict()\n",
        "  loaders[\"train\"] = train_loader\n",
        "  loaders[\"valid\"] = valid_loader\n",
        "\n",
        "  return loaders\n",
        "\n",
        "@register_model\n",
        "def resmlp_12_224(pretrained=False, **kwargs):\n",
        "  \"\"\" ResMLP-12\n",
        "  Paper: `ResMLP: Feedforward networks for image classification...` - https://arxiv.org/abs/2105.03404\n",
        "  \"\"\"\n",
        "  model_args = dict(\n",
        "      patch_size=16, num_blocks=12, embed_dim=384, mlp_ratio=4, block_layer=ResBlock, norm_layer=Affine, **kwargs)\n",
        "  model = _create_mixer('resmlp_12_224', pretrained=pretrained, **model_args)\n",
        "  return model\n",
        "\n",
        "model = create_model(\n",
        "    'resmlp_12_224',\n",
        "    pretrained=True,\n",
        "    num_classes=20)\n",
        "\n",
        "model_ema = ModelEma(\n",
        "    model,\n",
        "    decay=0.99,\n",
        "    device='cuda'\n",
        ")\n",
        "\n",
        "n_parameters = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "print('number of params:', n_parameters)\n",
        "\n",
        "linear_scaled_lr = 0.0001 * BATCH_SIZE * 1 / 512.0\n",
        "lr = linear_scaled_lr\n",
        "optimizer  = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "loss_scaler = NativeScaler()\n",
        "\n",
        "lr_scheduler =torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, 0.001)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "mixup_fn = Mixup(\n",
        "            mixup_alpha=0.2, cutmix_alpha=0.03, \n",
        "            prob=0.8, switch_prob=0.3, mode= 'batch', num_classes=20)\n",
        "\n",
        "@torch.no_grad()\n",
        "def evaluate(data_loader, model, device):\n",
        "    criterion = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "\n",
        "    # switch to evaluation mode\n",
        "    model.eval()\n",
        "    acc1_mean = 0.0\n",
        "    acc5_mean = 0.0\n",
        "    Batch = len(data_loader)\n",
        "    print('Total Batch:', Batch)\n",
        "    \n",
        "    for images, target in data_loader:\n",
        "        images = images.to(device, non_blocking=True)\n",
        "        target = target.to(device, non_blocking=True)\n",
        "\n",
        "        # compute output\n",
        "        with torch.cuda.amp.autocast():\n",
        "            output = model(images)\n",
        "            loss = criterion(output, target)\n",
        "\n",
        "        acc1, acc5 = accuracy(output, target, topk=(1, 5))\n",
        "        acc1_mean+=acc1.item()\n",
        "        acc5_mean+=acc5.item()\n",
        "        \n",
        "\n",
        "        batch_size = images.shape[0]\n",
        "    print('* Acc@1 {:.3f} Acc@5 {:.3f} loss {:.3f}'\n",
        "          .format(acc1_mean/Batch, acc5_mean/Batch, loss.item()))\n",
        "    \n",
        "def train_one_epoch(model, criterion, data_loader, optimizer,\n",
        "                    device, epoch, loss_scaler, max_norm,\n",
        "                    model_ema, mixup_fn):\n",
        "\n",
        "    model.train()\n",
        "    model.to(device)\n",
        "    header = 'Epoch: [{}]'.format(epoch)\n",
        "    print_freq = 50\n",
        "    count = 0\n",
        "    Batch = len(data_loader)\n",
        "    print('Total Batch:', Batch)\n",
        "    loss_mean = 0.0\n",
        "    for samples, targets in data_loader:\n",
        "        count +=1\n",
        "        samples = samples.to(device, non_blocking=True)\n",
        "        targets = targets.to(device, non_blocking=True)\n",
        "\n",
        "        if mixup_fn is not None:\n",
        "            samples, _ = mixup_fn(samples, targets)\n",
        "        with torch.cuda.amp.autocast():\n",
        "            outputs = model(samples)\n",
        "            \n",
        "            loss = criterion(outputs, targets)\n",
        "\n",
        "        loss_value = loss.item()\n",
        "        loss_mean += loss_value \n",
        "\n",
        "        if not math.isfinite(loss_value):\n",
        "            print(\"Loss is {}, stopping training\".format(loss_value))\n",
        "            sys.exit(1)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # this attribute is added by timm on one optimizer (adahessian)\n",
        "        is_second_order = hasattr(optimizer, 'is_second_order') and optimizer.is_second_order\n",
        "        loss_scaler(loss, optimizer, clip_grad=max_norm,\n",
        "                    parameters=model.parameters(), create_graph=is_second_order)\n",
        "\n",
        "        torch.cuda.synchronize()\n",
        "        if model_ema is not None:\n",
        "            model_ema.update(model)\n",
        "\n",
        "        if count % print_freq == 0:\n",
        "            current_time = datetime.now().strftime(\"%H:%M:%S\")\n",
        "            print(f'{current_time}\\tEPOCH: [{epoch}/10] STEP: [{count}/{Batch}], LOSS: {loss_mean/50}')\n",
        "            loss_mean = 0.0\n",
        "    torch.save({'model': model.state_dict(),\n",
        "                'optimizer': optimizer.state_dict(),\n",
        "                'lr_scheduler': lr_scheduler.state_dict(),\n",
        "                'epoch': epoch,\n",
        "                'model_ema': get_state_dict(model_ema),\n",
        "                }, MODEL_PATH)\n",
        "\n",
        "loaders = get_loaders()\n",
        "\n",
        "print(\"Start training\")\n",
        "max_accuracy = 0.0\n",
        "for epoch in range(0, 19):\n",
        "\n",
        "    train_stats = train_one_epoch(\n",
        "        model, criterion, loaders[\"train\"],\n",
        "        optimizer, 'cuda', epoch, loss_scaler,\n",
        "        None, model_ema, mixup_fn\n",
        "    )\n",
        "\n",
        "    lr_scheduler.step(epoch)\n",
        "    evaluate( loaders[\"valid\"], model, 'cuda')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**ResMLP24**"
      ],
      "metadata": {
        "id": "Xg3RWGVsW9Wb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install timm\n",
        "!CUDA_LAUNCH_BLOCKING=1\n",
        "import os\n",
        "import cv2\n",
        "import sys\n",
        "import json\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from functools import partial\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "from torch import nn\n",
        "from timm.utils import accuracy\n",
        "from timm.data import Mixup\n",
        "from timm.models import create_model\n",
        "from timm.loss import LabelSmoothingCrossEntropy, SoftTargetCrossEntropy\n",
        "from timm.scheduler import create_scheduler\n",
        "import torchvision.transforms as transforms\n",
        "from timm.optim import create_optimizer\n",
        "from timm.utils import NativeScaler, get_state_dict, ModelEma\n",
        "from timm.models.registry import register_model\n",
        "from timm.models.mlp_mixer import ResBlock, Affine, _create_mixer, _cfg\n",
        "from timm.models import create_model\n",
        "import torchvision\n",
        "import numpy as np\n",
        "import collections\n",
        "import math\n",
        "from datetime import datetime\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive/', force_remount=True)\n",
        "\n",
        "# Modify these code line by specifying the path of Train and Test data as well as the path for saving the model.\n",
        "TRAIN_PATH = \"/content/drive/Shareddrives/vit-ear/ViT-Ear/EarVN/train/\"\n",
        "TEST_PATH = \"/content/drive/Shareddrives/vit-ear/ViT-Ear/EarVN/val/\"\n",
        "MODEL_PATH = \"/content/drive/Shareddrives/vit-ear/ViT-Ear/EarVN/model/resmlp24.pth\"\n",
        "\n",
        "image_size = 224\n",
        "IMG_SIZE = 224\n",
        "BATCH_SIZE = 64\n",
        "LR = 2e-05\n",
        "GAMMA = 0.7\n",
        "N_EPOCHS = 20\n",
        "N_CLASSES = 20\n",
        "\n",
        "def get_loaders(batch_size = BATCH_SIZE, num_workers=2):\n",
        "  transforms_train = transforms.Compose(\n",
        "    [\n",
        "        transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
        "        transforms.RandomHorizontalFlip(p=0.3),\n",
        "        transforms.RandomVerticalFlip(p=0.3),\n",
        "        transforms.RandomResizedCrop(IMG_SIZE),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n",
        "    ])\n",
        "\n",
        "  transforms_valid = torchvision.transforms.Compose(\n",
        "      [\n",
        "          transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
        "          transforms.ToTensor(),\n",
        "          transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n",
        "      ]\n",
        "  )\n",
        "\n",
        "  train_dataset = torchvision.datasets.ImageFolder(TRAIN_PATH, transform = transforms_train)\n",
        "  valid_dataset = torchvision.datasets.ImageFolder(TEST_PATH, transform = transforms_valid)\n",
        "\n",
        "  train_loader = torch.utils.data.DataLoader(\n",
        "      train_dataset,\n",
        "      batch_size=batch_size,\n",
        "      shuffle=True,\n",
        "      num_workers=num_workers,\n",
        "      drop_last=True,\n",
        "    )\n",
        "\n",
        "  valid_loader = torch.utils.data.DataLoader(\n",
        "      valid_dataset,\n",
        "      batch_size=batch_size,\n",
        "      shuffle=False,\n",
        "      num_workers=num_workers,\n",
        "      drop_last=True,\n",
        "    )\n",
        "\n",
        "  loaders = collections.OrderedDict()\n",
        "  loaders[\"train\"] = train_loader\n",
        "  loaders[\"valid\"] = valid_loader\n",
        "\n",
        "  return loaders\n",
        "\n",
        "@register_model\n",
        "def resmlp_24_224(pretrained=False, **kwargs):\n",
        "  \"\"\" ResMLP-24\n",
        "  Paper: `ResMLP: Feedforward networks for image classification...` - https://arxiv.org/abs/2105.03404\n",
        "  \"\"\"\n",
        "  model_args = dict(\n",
        "      patch_size=16, num_blocks=24, embed_dim=384, mlp_ratio=4,\n",
        "      block_layer=partial(ResBlock, init_values=1e-5), norm_layer=Affine, **kwargs)\n",
        "  model = _create_mixer('resmlp_24_224', pretrained=pretrained, **model_args)\n",
        "  return model\n",
        "\n",
        "model = create_model(\n",
        "    'resmlp_24_224',\n",
        "    pretrained=True,\n",
        "    num_classes=20)\n",
        "\n",
        "model_ema = ModelEma(\n",
        "    model,\n",
        "    decay=0.99,\n",
        "    device='cuda'\n",
        ")\n",
        "\n",
        "n_parameters = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "print('number of params:', n_parameters)\n",
        "\n",
        "linear_scaled_lr = 0.0001 * BATCH_SIZE * 1 / 512.0\n",
        "lr = linear_scaled_lr\n",
        "optimizer  = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "loss_scaler = NativeScaler()\n",
        "\n",
        "lr_scheduler =torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, 0.001)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "mixup_fn = Mixup(\n",
        "            mixup_alpha=0.2, cutmix_alpha=0.03, \n",
        "            prob=0.8, switch_prob=0.3, mode= 'batch', num_classes=20)\n",
        "\n",
        "@torch.no_grad()\n",
        "def evaluate(data_loader, model, device):\n",
        "    criterion = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "\n",
        "    # switch to evaluation mode\n",
        "    model.eval()\n",
        "    acc1_mean = 0.0\n",
        "    acc5_mean = 0.0\n",
        "    Batch = len(data_loader)\n",
        "    print('Total Batch:', Batch)\n",
        "    \n",
        "    for images, target in data_loader:\n",
        "        images = images.to(device, non_blocking=True)\n",
        "        target = target.to(device, non_blocking=True)\n",
        "\n",
        "        # compute output\n",
        "        with torch.cuda.amp.autocast():\n",
        "            output = model(images)\n",
        "            loss = criterion(output, target)\n",
        "\n",
        "        acc1, acc5 = accuracy(output, target, topk=(1, 5))\n",
        "        acc1_mean+=acc1.item()\n",
        "        acc5_mean+=acc5.item()\n",
        "        \n",
        "\n",
        "        batch_size = images.shape[0]\n",
        "    print('* Acc@1 {:.3f} Acc@5 {:.3f} loss {:.3f}'\n",
        "          .format(acc1_mean/Batch, acc5_mean/Batch, loss.item()))\n",
        "    \n",
        "def train_one_epoch(model, criterion, data_loader, optimizer,\n",
        "                    device, epoch, loss_scaler, max_norm,\n",
        "                    model_ema, mixup_fn):\n",
        "\n",
        "    model.train()\n",
        "    model.to(device)\n",
        "    header = 'Epoch: [{}]'.format(epoch)\n",
        "    print_freq = 50\n",
        "    count = 0\n",
        "    Batch = len(data_loader)\n",
        "    print('Total Batch:', Batch)\n",
        "    loss_mean = 0.0\n",
        "    for samples, targets in data_loader:\n",
        "        count +=1\n",
        "        samples = samples.to(device, non_blocking=True)\n",
        "        targets = targets.to(device, non_blocking=True)\n",
        "\n",
        "        if mixup_fn is not None:\n",
        "            samples, _ = mixup_fn(samples, targets)\n",
        "        with torch.cuda.amp.autocast():\n",
        "            outputs = model(samples)\n",
        "            \n",
        "            loss = criterion(outputs, targets)\n",
        "\n",
        "        loss_value = loss.item()\n",
        "        loss_mean += loss_value \n",
        "\n",
        "        if not math.isfinite(loss_value):\n",
        "            print(\"Loss is {}, stopping training\".format(loss_value))\n",
        "            sys.exit(1)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # this attribute is added by timm on one optimizer (adahessian)\n",
        "        is_second_order = hasattr(optimizer, 'is_second_order') and optimizer.is_second_order\n",
        "        loss_scaler(loss, optimizer, clip_grad=max_norm,\n",
        "                    parameters=model.parameters(), create_graph=is_second_order)\n",
        "\n",
        "        torch.cuda.synchronize()\n",
        "        if model_ema is not None:\n",
        "            model_ema.update(model)\n",
        "\n",
        "        if count % print_freq == 0:\n",
        "            current_time = datetime.now().strftime(\"%H:%M:%S\")\n",
        "            print(f'{current_time}\\tEPOCH: [{epoch}/10] STEP: [{count}/{Batch}], LOSS: {loss_mean/50}')\n",
        "            loss_mean = 0.0\n",
        "    torch.save({'model': model.state_dict(),\n",
        "                'optimizer': optimizer.state_dict(),\n",
        "                'lr_scheduler': lr_scheduler.state_dict(),\n",
        "                'epoch': epoch,\n",
        "                'model_ema': get_state_dict(model_ema),\n",
        "                }, MODEL_PATH)\n",
        "\n",
        "loaders = get_loaders()\n",
        "\n",
        "print(\"Start training\")\n",
        "max_accuracy = 0.0\n",
        "for epoch in range(0, 19):\n",
        "\n",
        "    train_stats = train_one_epoch(\n",
        "        model, criterion, loaders[\"train\"],\n",
        "        optimizer, 'cuda', epoch, loss_scaler,\n",
        "        None, model_ema, mixup_fn\n",
        "    )\n",
        "\n",
        "    lr_scheduler.step(epoch)\n",
        "    evaluate( loaders[\"valid\"], model, 'cuda')\n"
      ],
      "metadata": {
        "id": "9Zmw4vDFW79F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**ResMLP36**"
      ],
      "metadata": {
        "id": "7uUV3UgUXYFz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install timm\n",
        "!CUDA_LAUNCH_BLOCKING=1\n",
        "import os\n",
        "import cv2\n",
        "import sys\n",
        "import json\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from functools import partial\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "from torch import nn\n",
        "from timm.utils import accuracy\n",
        "from timm.data import Mixup\n",
        "from timm.models import create_model\n",
        "from timm.loss import LabelSmoothingCrossEntropy, SoftTargetCrossEntropy\n",
        "from timm.scheduler import create_scheduler\n",
        "import torchvision.transforms as transforms\n",
        "from timm.optim import create_optimizer\n",
        "from timm.utils import NativeScaler, get_state_dict, ModelEma\n",
        "from timm.models.registry import register_model\n",
        "from timm.models.mlp_mixer import ResBlock, Affine, _create_mixer, _cfg\n",
        "from timm.models import create_model\n",
        "import torchvision\n",
        "import numpy as np\n",
        "import collections\n",
        "import math\n",
        "from datetime import datetime\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive/', force_remount=True)\n",
        "\n",
        "# Modify these code line by specifying the path of Train and Test data as well as the path for saving the model.\n",
        "TRAIN_PATH = \"/content/drive/Shareddrives/vit-ear/ViT-Ear/EarVN/train/\"\n",
        "TEST_PATH = \"/content/drive/Shareddrives/vit-ear/ViT-Ear/EarVN/val/\"\n",
        "MODEL_PATH = \"/content/drive/Shareddrives/vit-ear/ViT-Ear/EarVN/model/resmlp36.pth\"\n",
        "\n",
        "image_size = 224\n",
        "IMG_SIZE = 224\n",
        "BATCH_SIZE = 64\n",
        "LR = 2e-05\n",
        "GAMMA = 0.7\n",
        "N_EPOCHS = 250\n",
        "N_CLASSES = 20\n",
        "\n",
        "def get_loaders(batch_size = BATCH_SIZE, num_workers=2):\n",
        "  transforms_train = transforms.Compose(\n",
        "    [\n",
        "        transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
        "        transforms.RandomHorizontalFlip(p=0.3),\n",
        "        transforms.RandomVerticalFlip(p=0.3),\n",
        "        transforms.RandomResizedCrop(IMG_SIZE),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n",
        "    ])\n",
        "\n",
        "  transforms_valid = torchvision.transforms.Compose(\n",
        "      [\n",
        "          transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
        "          transforms.ToTensor(),\n",
        "          transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n",
        "      ]\n",
        "  )\n",
        "\n",
        "  train_dataset = torchvision.datasets.ImageFolder(TRAIN_PATH, transform = transforms_train)\n",
        "  valid_dataset = torchvision.datasets.ImageFolder(TEST_PATH, transform = transforms_valid)\n",
        "\n",
        "  train_loader = torch.utils.data.DataLoader(\n",
        "      train_dataset,\n",
        "      batch_size=batch_size,\n",
        "      shuffle=True,\n",
        "      num_workers=num_workers,\n",
        "      drop_last=True,\n",
        "    )\n",
        "\n",
        "  valid_loader = torch.utils.data.DataLoader(\n",
        "      valid_dataset,\n",
        "      batch_size=batch_size,\n",
        "      shuffle=False,\n",
        "      num_workers=num_workers,\n",
        "      drop_last=True,\n",
        "    )\n",
        "\n",
        "  loaders = collections.OrderedDict()\n",
        "  loaders[\"train\"] = train_loader\n",
        "  loaders[\"valid\"] = valid_loader\n",
        "\n",
        "  return loaders\n",
        "\n",
        "@register_model\n",
        "def resmlp_36_224(pretrained=False, **kwargs):\n",
        "  \"\"\" ResMLP-36\n",
        "  Paper: `ResMLP: Feedforward networks for image classification...` - https://arxiv.org/abs/2105.03404\n",
        "  \"\"\"\n",
        "  model_args = dict(\n",
        "      patch_size=16, num_blocks=36, embed_dim=384, mlp_ratio=4,\n",
        "      block_layer=partial(ResBlock, init_values=1e-6), norm_layer=Affine, **kwargs)\n",
        "  model = _create_mixer('resmlp_36_224', pretrained=pretrained, **model_args)\n",
        "  return model\n",
        "\n",
        "model = create_model(\n",
        "    'resmlp_36_224',\n",
        "    pretrained=True,\n",
        "    num_classes=20)\n",
        "\n",
        "model_ema = ModelEma(\n",
        "    model,\n",
        "    decay=0.99,\n",
        "    device='cuda'\n",
        ")\n",
        "\n",
        "n_parameters = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "print('number of params:', n_parameters)\n",
        "\n",
        "linear_scaled_lr = 0.0001 * BATCH_SIZE * 1 / 512.0\n",
        "lr = linear_scaled_lr\n",
        "optimizer  = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "loss_scaler = NativeScaler()\n",
        "\n",
        "lr_scheduler =torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, 0.001)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "mixup_fn = Mixup(\n",
        "            mixup_alpha=0.2, cutmix_alpha=0.03, \n",
        "            prob=0.8, switch_prob=0.3, mode= 'batch', num_classes=20)\n",
        "\n",
        "@torch.no_grad()\n",
        "def evaluate(data_loader, model, device):\n",
        "    criterion = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "\n",
        "    # switch to evaluation mode\n",
        "    model.eval()\n",
        "    acc1_mean = 0.0\n",
        "    acc5_mean = 0.0\n",
        "    Batch = len(data_loader)\n",
        "    print('Total Batch:', Batch)\n",
        "    \n",
        "    for images, target in data_loader:\n",
        "        images = images.to(device, non_blocking=True)\n",
        "        target = target.to(device, non_blocking=True)\n",
        "\n",
        "        # compute output\n",
        "        with torch.cuda.amp.autocast():\n",
        "            output = model(images)\n",
        "            loss = criterion(output, target)\n",
        "\n",
        "        acc1, acc5 = accuracy(output, target, topk=(1, 5))\n",
        "        acc1_mean+=acc1.item()\n",
        "        acc5_mean+=acc5.item()\n",
        "        \n",
        "\n",
        "        batch_size = images.shape[0]\n",
        "    print('* Acc@1 {:.3f} Acc@5 {:.3f} loss {:.3f}'\n",
        "          .format(acc1_mean/Batch, acc5_mean/Batch, loss.item()))\n",
        "    \n",
        "def train_one_epoch(model, criterion, data_loader, optimizer,\n",
        "                    device, epoch, loss_scaler, max_norm,\n",
        "                    model_ema, mixup_fn):\n",
        "\n",
        "    model.train()\n",
        "    model.to(device)\n",
        "    header = 'Epoch: [{}]'.format(epoch)\n",
        "    print_freq = 50\n",
        "    count = 0\n",
        "    Batch = len(data_loader)\n",
        "    print('Total Batch:', Batch)\n",
        "    loss_mean = 0.0\n",
        "    for samples, targets in data_loader:\n",
        "        count +=1\n",
        "        samples = samples.to(device, non_blocking=True)\n",
        "        targets = targets.to(device, non_blocking=True)\n",
        "\n",
        "        if mixup_fn is not None:\n",
        "            samples, _ = mixup_fn(samples, targets)\n",
        "        with torch.cuda.amp.autocast():\n",
        "            outputs = model(samples)\n",
        "            \n",
        "            loss = criterion(outputs, targets)\n",
        "\n",
        "        loss_value = loss.item()\n",
        "        loss_mean += loss_value \n",
        "\n",
        "        if not math.isfinite(loss_value):\n",
        "            print(\"Loss is {}, stopping training\".format(loss_value))\n",
        "            sys.exit(1)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # this attribute is added by timm on one optimizer (adahessian)\n",
        "        is_second_order = hasattr(optimizer, 'is_second_order') and optimizer.is_second_order\n",
        "        loss_scaler(loss, optimizer, clip_grad=max_norm,\n",
        "                    parameters=model.parameters(), create_graph=is_second_order)\n",
        "\n",
        "        torch.cuda.synchronize()\n",
        "        if model_ema is not None:\n",
        "            model_ema.update(model)\n",
        "\n",
        "        if count % print_freq == 0:\n",
        "            current_time = datetime.now().strftime(\"%H:%M:%S\")\n",
        "            print(f'{current_time}\\tEPOCH: [{epoch}/10] STEP: [{count}/{Batch}], LOSS: {loss_mean/50}')\n",
        "            loss_mean = 0.0\n",
        "    torch.save({'model': model.state_dict(),\n",
        "                'optimizer': optimizer.state_dict(),\n",
        "                'lr_scheduler': lr_scheduler.state_dict(),\n",
        "                'epoch': epoch,\n",
        "                'model_ema': get_state_dict(model_ema),\n",
        "                }, MODEL_PATH)\n",
        "\n",
        "loaders = get_loaders()\n",
        "\n",
        "print(\"Start training\")\n",
        "max_accuracy = 0.0\n",
        "for epoch in range(0, 249):\n",
        "\n",
        "    train_stats = train_one_epoch(\n",
        "        model, criterion, loaders[\"train\"],\n",
        "        optimizer, 'cuda', epoch, loss_scaler,\n",
        "        None, model_ema, mixup_fn\n",
        "    )\n",
        "\n",
        "    lr_scheduler.step(epoch)\n",
        "    evaluate( loaders[\"valid\"], model, 'cuda')\n"
      ],
      "metadata": {
        "id": "cULm5EA4XavF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**MLP-Mixer**"
      ],
      "metadata": {
        "id": "ysGygpH8Xn2F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install timm\n",
        "!CUDA_LAUNCH_BLOCKING=1\n",
        "import os\n",
        "import cv2\n",
        "import sys\n",
        "import json\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from functools import partial\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "from torch import nn\n",
        "from timm.utils import accuracy\n",
        "from timm.data import Mixup\n",
        "from timm.models import create_model\n",
        "from timm.loss import LabelSmoothingCrossEntropy, SoftTargetCrossEntropy\n",
        "from timm.scheduler import create_scheduler\n",
        "import torchvision.transforms as transforms\n",
        "from timm.optim import create_optimizer\n",
        "from timm.utils import NativeScaler, get_state_dict, ModelEma\n",
        "from timm.models.registry import register_model\n",
        "from timm.models.mlp_mixer import ResBlock, Affine, _create_mixer, MlpMixer, _cfg\n",
        "from timm.models import create_model\n",
        "import torchvision\n",
        "import numpy as np\n",
        "import collections\n",
        "import math\n",
        "from datetime import datetime\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive/', force_remount=True)\n",
        "\n",
        "# Modify these code line by specifying the path of Train and Test data as well as the path for saving the model.\n",
        "TRAIN_PATH = \"/content/drive/MyDrive/Colab_Notebooks/ViT-Ear/EarVN/train/\"\n",
        "TEST_PATH = \"/content/drive/MyDrive/Colab_Notebooks/ViT-Ear/EarVN/val/\"\n",
        "MODEL_PATH = \"/content/drive/MyDrive/Colab_Notebooks/ViT-Ear/EarVN/model/resmlp.pth\"\n",
        "\n",
        "image_size = 224\n",
        "IMG_SIZE = 224\n",
        "BATCH_SIZE = 32\n",
        "LR = 2e-05\n",
        "GAMMA = 0.7\n",
        "N_EPOCHS = 20\n",
        "N_CLASSES = 20\n",
        "\n",
        "def get_loaders(batch_size = BATCH_SIZE, num_workers=2):\n",
        "  transforms_train = transforms.Compose(\n",
        "    [\n",
        "        transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
        "        transforms.RandomHorizontalFlip(p=0.3),\n",
        "        transforms.RandomVerticalFlip(p=0.3),\n",
        "        transforms.RandomResizedCrop(IMG_SIZE),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n",
        "    ])\n",
        "\n",
        "  transforms_valid = torchvision.transforms.Compose(\n",
        "      [\n",
        "          transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
        "          transforms.ToTensor(),\n",
        "          transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n",
        "      ]\n",
        "  )\n",
        "\n",
        "  train_dataset = torchvision.datasets.ImageFolder(TRAIN_PATH, transform = transforms_train)\n",
        "  valid_dataset = torchvision.datasets.ImageFolder(TEST_PATH, transform = transforms_valid)\n",
        "\n",
        "  train_loader = torch.utils.data.DataLoader(\n",
        "      train_dataset,\n",
        "      batch_size=batch_size,\n",
        "      shuffle=True,\n",
        "      num_workers=num_workers,\n",
        "      drop_last=True,\n",
        "    )\n",
        "\n",
        "  valid_loader = torch.utils.data.DataLoader(\n",
        "      valid_dataset,\n",
        "      batch_size=batch_size,\n",
        "      shuffle=False,\n",
        "      num_workers=num_workers,\n",
        "      drop_last=True,\n",
        "    )\n",
        "\n",
        "  loaders = collections.OrderedDict()\n",
        "  loaders[\"train\"] = train_loader\n",
        "  loaders[\"valid\"] = valid_loader\n",
        "  return loaders\n",
        "\n",
        "@register_model\n",
        "def mixer_l16_224(pretrained=False, **kwargs):\n",
        "  \"\"\" Mixer-L/16 224x224. ImageNet-1k pretrained weights.\n",
        "  Paper:  'MLP-Mixer: An all-MLP Architecture for Vision' - https://arxiv.org/abs/2105.01601\n",
        "  \"\"\"\n",
        "  model_args = dict(patch_size=16, num_blocks=24, embed_dim=1024, **kwargs)\n",
        "  model = _create_mixer('mixer_l16_224', pretrained=pretrained, **model_args)\n",
        "  return model\n",
        "\n",
        "model = create_model(\n",
        "    'mixer_l16_224',\n",
        "    pretrained=True,\n",
        "    num_classes=20)\n",
        "\n",
        "model_ema = ModelEma(\n",
        "    model,\n",
        "    decay=0.99,\n",
        "    device='cuda'\n",
        ")\n",
        "\n",
        "n_parameters = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "print('number of params:', n_parameters)\n",
        "\n",
        "linear_scaled_lr = 0.0001 * BATCH_SIZE * 1 / 512.0\n",
        "lr = linear_scaled_lr\n",
        "optimizer  = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "loss_scaler = NativeScaler()\n",
        "\n",
        "lr_scheduler =torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, 0.001)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "mixup_fn = Mixup(\n",
        "            mixup_alpha=0.2, cutmix_alpha=0.03, \n",
        "            prob=0.8, switch_prob=0.3, mode= 'batch', num_classes=20)\n",
        "\n",
        "@torch.no_grad()\n",
        "def evaluate(data_loader, model, device):\n",
        "    criterion = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "\n",
        "    # switch to evaluation mode\n",
        "    model.eval()\n",
        "    acc1_mean = 0.0\n",
        "    acc5_mean = 0.0\n",
        "    Batch = len(data_loader)\n",
        "    print('Total Batch:', Batch)\n",
        "    \n",
        "    for images, target in data_loader:\n",
        "        images = images.to(device, non_blocking=True)\n",
        "        target = target.to(device, non_blocking=True)\n",
        "\n",
        "        # compute output\n",
        "        with torch.cuda.amp.autocast():\n",
        "            output = model(images)\n",
        "            loss = criterion(output, target)\n",
        "\n",
        "        acc1, acc5 = accuracy(output, target, topk=(1, 5))\n",
        "        acc1_mean+=acc1.item()\n",
        "        acc5_mean+=acc5.item()\n",
        "        \n",
        "\n",
        "        batch_size = images.shape[0]\n",
        "    print('* Acc@1 {:.3f} Acc@5 {:.3f} loss {:.3f}'\n",
        "          .format(acc1_mean/Batch, acc5_mean/Batch, loss.item()))\n",
        "    \n",
        "def train_one_epoch(model, criterion, data_loader, optimizer,\n",
        "                    device, epoch, loss_scaler, max_norm,\n",
        "                    model_ema, mixup_fn):\n",
        "\n",
        "    model.train()\n",
        "    model.to(device)\n",
        "    header = 'Epoch: [{}]'.format(epoch)\n",
        "    print_freq = 50\n",
        "    count = 0\n",
        "    Batch = len(data_loader)\n",
        "    print('Total Batch:', Batch)\n",
        "    loss_mean = 0.0\n",
        "    for samples, targets in data_loader:\n",
        "        count +=1\n",
        "        samples = samples.to(device, non_blocking=True)\n",
        "        targets = targets.to(device, non_blocking=True)\n",
        "\n",
        "        if mixup_fn is not None:\n",
        "            samples, _ = mixup_fn(samples, targets)\n",
        "        with torch.cuda.amp.autocast():\n",
        "            outputs = model(samples)\n",
        "            \n",
        "            loss = criterion(outputs, targets)\n",
        "\n",
        "        loss_value = loss.item()\n",
        "        loss_mean += loss_value \n",
        "\n",
        "        if not math.isfinite(loss_value):\n",
        "            print(\"Loss is {}, stopping training\".format(loss_value))\n",
        "            sys.exit(1)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # this attribute is added by timm on one optimizer (adahessian)\n",
        "        is_second_order = hasattr(optimizer, 'is_second_order') and optimizer.is_second_order\n",
        "        loss_scaler(loss, optimizer, clip_grad=max_norm,\n",
        "                    parameters=model.parameters(), create_graph=is_second_order)\n",
        "\n",
        "        torch.cuda.synchronize()\n",
        "        if model_ema is not None:\n",
        "            model_ema.update(model)\n",
        "\n",
        "        if count % print_freq == 0:\n",
        "            current_time = datetime.now().strftime(\"%H:%M:%S\")\n",
        "            print(f'{current_time}\\tEPOCH: [{epoch}/10] STEP: [{count}/{Batch}], LOSS: {loss_mean/50}')\n",
        "            loss_mean = 0.0\n",
        "    torch.save({'model': model.state_dict(),\n",
        "                'optimizer': optimizer.state_dict(),\n",
        "                'lr_scheduler': lr_scheduler.state_dict(),\n",
        "                'epoch': epoch,\n",
        "                'model_ema': get_state_dict(model_ema),\n",
        "                }, MODEL_PATH)\n",
        "\n",
        "loaders = get_loaders()\n",
        "\n",
        "print(\"Start training\")\n",
        "max_accuracy = 0.0\n",
        "for epoch in range(0, 19):\n",
        "\n",
        "    train_stats = train_one_epoch(\n",
        "        model, criterion, loaders[\"train\"],\n",
        "        optimizer, 'cuda', epoch, loss_scaler,\n",
        "        None, model_ema, mixup_fn\n",
        "    )\n",
        "\n",
        "    lr_scheduler.step(epoch)\n",
        "    evaluate( loaders[\"valid\"], model, 'cuda')\n",
        "\n",
        "# 4hours training."
      ],
      "metadata": {
        "id": "O3z2G8yNXq5V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**[Rough codes and execution are in this link.](https://colab.research.google.com/drive/141bKNrPtKnraKSpJXNjUvJjOG6Gpl3Ij?usp=sharing)**\n",
        "\n"
      ],
      "metadata": {
        "id": "-D2H2XS_cTEO"
      }
    }
  ]
}